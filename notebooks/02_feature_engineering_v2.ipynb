{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”§ Feature Engineering V2: Crohn vs CU Separado\n",
    "\n",
    "**Objetivo:** Crear features para predecir el riesgo de brotes en pacientes con Crohn y CU **por separado**\n",
    "\n",
    "**Input:** \n",
    "- `../data/processed/crohn_filtered.csv` (del notebook 01 V2)\n",
    "- `../data/processed/cu_filtered.csv` (del notebook 01 V2)\n",
    "\n",
    "**Output:** Datasets estructurados con features para entrenamiento:\n",
    "- `../data/processed/crohn/ml_dataset.csv`\n",
    "- `../data/processed/cu/ml_dataset.csv`\n",
    "\n",
    "**Mejoras vs V1:**\n",
    "- Procesa Crohn y CU independientemente\n",
    "- Permite ajustar severity scoring para cada tipo\n",
    "- Genera datasets separados para modelos especÃ­ficos\n",
    "\n",
    "**Autor:** Asier Ortiz GarcÃ­a  \n",
    "**Fecha:** Noviembre 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Imports y ConfiguraciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import json\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "%matplotlib inline\n",
    "\n",
    "# Crear directorios\n",
    "Path('../data/processed/crohn').mkdir(parents=True, exist_ok=True)\n",
    "Path('../data/processed/cu').mkdir(parents=True, exist_ok=True)\n",
    "Path('../docs/figures').mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE ENGINEERING V2: Crohn vs CU\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”„ Funciones Reutilizables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapeo de sÃ­ntomas\n",
    "SYMPTOM_MAPPING = {\n",
    "    'abdominal_pain': [\n",
    "        'abdominal pain', 'stomach pain', 'belly pain', 'cramping',\n",
    "        'abdominal cramps', 'stomach cramps', 'pain'\n",
    "    ],\n",
    "    'diarrhea': [\n",
    "        'diarrhea', 'loose stools', 'watery stools', 'frequent bowel movements',\n",
    "        'urgent bowel movements', 'urgency'\n",
    "    ],\n",
    "    'fatigue': [\n",
    "        'fatigue', 'tired', 'exhaustion', 'tiredness', 'weakness',\n",
    "        'lack of energy', 'low energy'\n",
    "    ],\n",
    "    'fever': [\n",
    "        'fever', 'high temperature', 'chills'\n",
    "    ],\n",
    "    'blood_in_stool': [\n",
    "        'blood in stool', 'bloody stool', 'rectal bleeding', 'bleeding'\n",
    "    ],\n",
    "    'nausea': [\n",
    "        'nausea', 'nauseous', 'feeling sick', 'queasiness', 'vomiting'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Pesos de sÃ­ntomas (ajustables por tipo de IBD si es necesario)\n",
    "SYMPTOM_WEIGHTS_CROHN = {\n",
    "    'abdominal_pain': 0.25,\n",
    "    'diarrhea': 0.25,\n",
    "    'fatigue': 0.15,\n",
    "    'blood_in_stool': 0.20,\n",
    "    'fever': 0.10,\n",
    "    'nausea': 0.05\n",
    "}\n",
    "\n",
    "SYMPTOM_WEIGHTS_UC = {\n",
    "    'abdominal_pain': 0.20,\n",
    "    'diarrhea': 0.25,\n",
    "    'fatigue': 0.15,\n",
    "    'blood_in_stool': 0.25,  # MÃ¡s peso en CU\n",
    "    'fever': 0.10,\n",
    "    'nausea': 0.05\n",
    "}\n",
    "\n",
    "def categorize_symptom(symptom_name):\n",
    "    \"\"\"Categoriza un sÃ­ntoma en una de nuestras categorÃ­as.\"\"\"\n",
    "    if pd.isna(symptom_name):\n",
    "        return None\n",
    "    \n",
    "    symptom_lower = str(symptom_name).lower()\n",
    "    \n",
    "    for category, keywords in SYMPTOM_MAPPING.items():\n",
    "        for keyword in keywords:\n",
    "            if keyword in symptom_lower:\n",
    "                return category\n",
    "    \n",
    "    return 'other'\n",
    "\n",
    "def classify_risk(score):\n",
    "    \"\"\"Clasificar severity score en risk level.\"\"\"\n",
    "    if score < 0.3:\n",
    "        return 'low'\n",
    "    elif score < 0.6:\n",
    "        return 'medium'\n",
    "    else:\n",
    "        return 'high'\n",
    "\n",
    "print(\"âœ“ Funciones definidas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ibd_data(df, ibd_type='crohn', symptom_weights=None):\n",
    "    \"\"\"\n",
    "    Procesar datos de un tipo de IBD especÃ­fico.\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame con datos filtrados\n",
    "        ibd_type: 'crohn' o 'cu'\n",
    "        symptom_weights: Dict con pesos para cada sÃ­ntoma\n",
    "    \n",
    "    Returns:\n",
    "        ml_dataset: DataFrame listo para entrenamiento\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PROCESANDO: {ibd_type.upper()}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    if symptom_weights is None:\n",
    "        symptom_weights = SYMPTOM_WEIGHTS_CROHN\n",
    "    \n",
    "    # 1. Procesar sÃ­ntomas\n",
    "    print(\"1ï¸âƒ£ Procesando sÃ­ntomas...\")\n",
    "    symptoms = df[df['trackable_type'] == 'Symptom'].copy()\n",
    "    symptoms['symptom_category'] = symptoms['trackable_name'].apply(categorize_symptom)\n",
    "    symptoms['value_numeric'] = pd.to_numeric(symptoms['trackable_value'], errors='coerce')\n",
    "    \n",
    "    # Filtrar valores vÃ¡lidos y sÃ­ntomas principales\n",
    "    symptoms_clean = symptoms[\n",
    "        (symptoms['value_numeric'] >= 0) & \n",
    "        (symptoms['value_numeric'] <= 4) &\n",
    "        (symptoms['symptom_category'].isin(list(SYMPTOM_MAPPING.keys())))\n",
    "    ].copy()\n",
    "    \n",
    "    symptoms_clean['severity_normalized'] = symptoms_clean['value_numeric'] / 4.0\n",
    "    \n",
    "    print(f\"  SÃ­ntomas procesados: {len(symptoms_clean):,}\")\n",
    "    print(f\"  DistribuciÃ³n:\")\n",
    "    print(f\"  {symptoms_clean['symptom_category'].value_counts()}\")\n",
    "    \n",
    "    # 2. Agregar por usuario y fecha\n",
    "    print(\"\\n2ï¸âƒ£ Agregando por usuario-fecha...\")\n",
    "    daily_symptoms = symptoms_clean.groupby(\n",
    "        ['user_id', 'checkin_date', 'symptom_category']\n",
    "    )['severity_normalized'].max().reset_index()\n",
    "    \n",
    "    daily_pivot = daily_symptoms.pivot_table(\n",
    "        index=['user_id', 'checkin_date'],\n",
    "        columns='symptom_category',\n",
    "        values='severity_normalized',\n",
    "        fill_value=0.0\n",
    "    ).reset_index()\n",
    "    \n",
    "    print(f\"  Registros diarios: {len(daily_pivot):,}\")\n",
    "    print(f\"  Usuarios: {daily_pivot['user_id'].nunique():,}\")\n",
    "    \n",
    "    # 3. Calcular severity score\n",
    "    print(\"\\n3ï¸âƒ£ Calculando severity score...\")\n",
    "    symptom_cols = [col for col in daily_pivot.columns if col in SYMPTOM_MAPPING.keys()]\n",
    "    daily_pivot['severity_score'] = 0.0\n",
    "    \n",
    "    for symptom in symptom_cols:\n",
    "        weight = symptom_weights.get(symptom, 0.1)\n",
    "        daily_pivot['severity_score'] += daily_pivot[symptom] * weight\n",
    "    \n",
    "    daily_pivot['risk_level'] = daily_pivot['severity_score'].apply(classify_risk)\n",
    "    \n",
    "    print(f\"  DistribuciÃ³n risk levels:\")\n",
    "    print(f\"  {daily_pivot['risk_level'].value_counts()}\")\n",
    "    \n",
    "    # 4. Features demogrÃ¡ficos\n",
    "    print(\"\\n4ï¸âƒ£ AÃ±adiendo features demogrÃ¡ficos...\")\n",
    "    demographics = df[['user_id', 'age', 'sex']].drop_duplicates('user_id')\n",
    "    daily_pivot = daily_pivot.merge(demographics, on='user_id', how='left')\n",
    "    \n",
    "    daily_pivot['age'].fillna(daily_pivot['age'].median(), inplace=True)\n",
    "    daily_pivot['sex'].fillna('unknown', inplace=True)\n",
    "    \n",
    "    gender_map = {'male': 'M', 'female': 'F', 'unknown': 'O', 'other': 'O'}\n",
    "    daily_pivot['gender'] = daily_pivot['sex'].map(gender_map).fillna('O')\n",
    "    \n",
    "    print(f\"  Age: media={daily_pivot['age'].mean():.1f}, mediana={daily_pivot['age'].median():.1f}\")\n",
    "    print(f\"  Gender: {daily_pivot['gender'].value_counts().to_dict()}\")\n",
    "    \n",
    "    # 5. Disease duration\n",
    "    print(\"\\n5ï¸âƒ£ Calculando disease duration...\")\n",
    "    first_checkin = df.groupby('user_id')['checkin_date'].min().reset_index()\n",
    "    first_checkin.columns = ['user_id', 'first_checkin']\n",
    "    daily_pivot = daily_pivot.merge(first_checkin, on='user_id', how='left')\n",
    "    \n",
    "    daily_pivot['days_since_first_checkin'] = (\n",
    "        daily_pivot['checkin_date'] - daily_pivot['first_checkin']\n",
    "    ).dt.days\n",
    "    daily_pivot['disease_duration_years'] = (daily_pivot['days_since_first_checkin'] / 365.25).fillna(0)\n",
    "    \n",
    "    print(f\"  Media: {daily_pivot['disease_duration_years'].mean():.2f} aÃ±os\")\n",
    "    \n",
    "    # 6. Previous flares y days since last flare\n",
    "    print(\"\\n6ï¸âƒ£ Calculando historial de brotes...\")\n",
    "    daily_pivot = daily_pivot.sort_values(['user_id', 'checkin_date'])\n",
    "    daily_pivot['is_flare_day'] = (daily_pivot['risk_level'] == 'high').astype(int)\n",
    "    daily_pivot['cumulative_flare_days'] = daily_pivot.groupby('user_id')['is_flare_day'].cumsum()\n",
    "    daily_pivot['previous_flares'] = (daily_pivot['cumulative_flare_days'] / 7).astype(int)\n",
    "    \n",
    "    def calc_days_since_flare(group):\n",
    "        group = group.sort_values('checkin_date')\n",
    "        last_flare_date = None\n",
    "        days_since = []\n",
    "        \n",
    "        for idx, row in group.iterrows():\n",
    "            if last_flare_date is None:\n",
    "                days_since.append(365)\n",
    "            else:\n",
    "                days = (row['checkin_date'] - last_flare_date).days\n",
    "                days_since.append(days)\n",
    "            \n",
    "            if row['risk_level'] == 'high':\n",
    "                last_flare_date = row['checkin_date']\n",
    "        \n",
    "        group['last_flare_days_ago'] = days_since\n",
    "        return group\n",
    "    \n",
    "    daily_pivot = daily_pivot.groupby('user_id', group_keys=False).apply(calc_days_since_flare)\n",
    "    \n",
    "    print(f\"  Previous flares: media={daily_pivot['previous_flares'].mean():.2f}\")\n",
    "    print(f\"  Days since last flare: media={daily_pivot['last_flare_days_ago'].mean():.1f}\")\n",
    "    \n",
    "    # 7. Features temporales\n",
    "    print(\"\\n7ï¸âƒ£ AÃ±adiendo features temporales...\")\n",
    "    daily_pivot['month'] = daily_pivot['checkin_date'].dt.month\n",
    "    daily_pivot['day_of_week'] = daily_pivot['checkin_date'].dt.dayofweek\n",
    "    \n",
    "    # 8. Dataset final\n",
    "    print(\"\\n8ï¸âƒ£ Preparando dataset final...\")\n",
    "    symptom_features = [col for col in symptom_cols if col in daily_pivot.columns]\n",
    "    demographic_features = ['age', 'gender']\n",
    "    history_features = ['disease_duration_years', 'previous_flares', 'last_flare_days_ago']\n",
    "    temporal_features = ['month', 'day_of_week']\n",
    "    target = 'risk_level'\n",
    "    \n",
    "    all_features = symptom_features + demographic_features + history_features + temporal_features\n",
    "    ml_dataset = daily_pivot[all_features + [target, 'user_id', 'checkin_date']].copy()\n",
    "    \n",
    "    # Imputar valores faltantes\n",
    "    for col in all_features:\n",
    "        if ml_dataset[col].dtype in ['float64', 'int64']:\n",
    "            ml_dataset[col].fillna(ml_dataset[col].median(), inplace=True)\n",
    "        else:\n",
    "            if len(ml_dataset[col].mode()) > 0:\n",
    "                ml_dataset[col].fillna(ml_dataset[col].mode()[0], inplace=True)\n",
    "    \n",
    "    print(f\"  âœ“ Dataset final: {len(ml_dataset):,} registros\")\n",
    "    print(f\"  âœ“ Features: {len(all_features)}\")\n",
    "    print(f\"  âœ“ Usuarios: {ml_dataset['user_id'].nunique():,}\")\n",
    "    \n",
    "    # Metadata\n",
    "    metadata = {\n",
    "        'ibd_type': ibd_type,\n",
    "        'features': all_features,\n",
    "        'symptom_features': symptom_features,\n",
    "        'demographic_features': demographic_features,\n",
    "        'history_features': history_features,\n",
    "        'temporal_features': temporal_features,\n",
    "        'target': target,\n",
    "        'n_samples': len(ml_dataset),\n",
    "        'n_users': int(ml_dataset['user_id'].nunique()),\n",
    "        'class_distribution': ml_dataset[target].value_counts().to_dict()\n",
    "    }\n",
    "    \n",
    "    return ml_dataset, metadata\n",
    "\n",
    "print(\"âœ“ FunciÃ³n de procesamiento definida\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Procesar Crohn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ“Š Cargando datos de Crohn...\\n\")\n",
    "df_crohn = pd.read_csv('../data/processed/crohn_filtered.csv')\n",
    "df_crohn['checkin_date'] = pd.to_datetime(df_crohn['checkin_date'])\n",
    "\n",
    "print(f\"âœ“ Cargado: {len(df_crohn):,} registros\")\n",
    "print(f\"âœ“ Usuarios: {df_crohn['user_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar Crohn\n",
    "crohn_dataset, crohn_metadata = process_ibd_data(\n",
    "    df_crohn,\n",
    "    ibd_type='crohn',\n",
    "    symptom_weights=SYMPTOM_WEIGHTS_CROHN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar Crohn\n",
    "print(\"\\nðŸ’¾ Guardando dataset de Crohn...\")\n",
    "crohn_dataset.to_csv('../data/processed/crohn/ml_dataset.csv', index=False)\n",
    "\n",
    "with open('../data/processed/crohn/ml_dataset_metadata.json', 'w') as f:\n",
    "    json.dump(crohn_metadata, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Crohn dataset guardado:\")\n",
    "print(f\"  - ../data/processed/crohn/ml_dataset.csv ({len(crohn_dataset):,} registros)\")\n",
    "print(f\"  - ../data/processed/crohn/ml_dataset_metadata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š Procesar Colitis Ulcerosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nðŸ“Š Cargando datos de CU...\\n\")\n",
    "df_cu = pd.read_csv('../data/processed/cu_filtered.csv')\n",
    "df_cu['checkin_date'] = pd.to_datetime(df_cu['checkin_date'])\n",
    "\n",
    "print(f\"âœ“ Cargado: {len(df_cu):,} registros\")\n",
    "print(f\"âœ“ Usuarios: {df_cu['user_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procesar CU\n",
    "cu_dataset, cu_metadata = process_ibd_data(\n",
    "    df_cu,\n",
    "    ibd_type='cu',\n",
    "    symptom_weights=SYMPTOM_WEIGHTS_UC\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar CU\n",
    "print(\"\\nðŸ’¾ Guardando dataset de CU...\")\n",
    "cu_dataset.to_csv('../data/processed/cu/ml_dataset.csv', index=False)\n",
    "\n",
    "with open('../data/processed/cu/ml_dataset_metadata.json', 'w') as f:\n",
    "    json.dump(cu_metadata, f, indent=2)\n",
    "\n",
    "print(f\"âœ… CU dataset guardado:\")\n",
    "print(f\"  - ../data/processed/cu/ml_dataset.csv ({len(cu_dataset):,} registros)\")\n",
    "print(f\"  - ../data/processed/cu/ml_dataset_metadata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“Š ComparaciÃ³n Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN COMPARATIVO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nðŸ“Š CROHN:\")\n",
    "print(f\"  Registros: {len(crohn_dataset):,}\")\n",
    "print(f\"  Usuarios: {crohn_metadata['n_users']:,}\")\n",
    "print(f\"  DistribuciÃ³n:\")\n",
    "for level, count in crohn_metadata['class_distribution'].items():\n",
    "    pct = count / len(crohn_dataset) * 100\n",
    "    print(f\"    {level}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nðŸ“Š CU:\")\n",
    "print(f\"  Registros: {len(cu_dataset):,}\")\n",
    "print(f\"  Usuarios: {cu_metadata['n_users']:,}\")\n",
    "print(f\"  DistribuciÃ³n:\")\n",
    "for level, count in cu_metadata['class_distribution'].items():\n",
    "    pct = count / len(cu_dataset) * 100\n",
    "    print(f\"    {level}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… FEATURE ENGINEERING V2 COMPLETADO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nPrÃ³ximos pasos:\")\n",
    "print(\"  1. Notebook 04: Entrenar modelos cluster-stratified para Crohn\")\n",
    "print(\"  2. Notebook 05: Entrenar modelos cluster-stratified para CU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“ˆ VisualizaciÃ³n Comparativa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Crohn distribution\n",
    "crohn_counts = crohn_dataset['risk_level'].value_counts()\n",
    "colors_dict = {'low': 'green', 'medium': 'orange', 'high': 'red'}\n",
    "axes[0].bar(crohn_counts.index, crohn_counts.values,\n",
    "           color=[colors_dict.get(x, 'gray') for x in crohn_counts.index],\n",
    "           edgecolor='black')\n",
    "axes[0].set_title('DistribuciÃ³n Risk Levels - CROHN', fontweight='bold', fontsize=12)\n",
    "axes[0].set_xlabel('Risk Level')\n",
    "axes[0].set_ylabel('Frecuencia')\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# CU distribution\n",
    "cu_counts = cu_dataset['risk_level'].value_counts()\n",
    "axes[1].bar(cu_counts.index, cu_counts.values,\n",
    "           color=[colors_dict.get(x, 'gray') for x in cu_counts.index],\n",
    "           edgecolor='black')\n",
    "axes[1].set_title('DistribuciÃ³n Risk Levels - CU', fontweight='bold', fontsize=12)\n",
    "axes[1].set_xlabel('Risk Level')\n",
    "axes[1].set_ylabel('Frecuencia')\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/figures/risk_distribution_crohn_vs_cu.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"ðŸ’¾ Figura guardada: ../docs/figures/risk_distribution_crohn_vs_cu.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

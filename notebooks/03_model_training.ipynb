{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udfaf Model Training: Cluster-Stratified Random Forest\n\n**Objetivo:** Entrenar modelos cluster-stratified para Crohn y CU\n\n**Input:**\n- `../data/processed/crohn/ml_dataset_enhanced.csv`\n- `../data/processed/cu/ml_dataset_enhanced.csv`\n- `../data/processed/crohn/user_clusters.csv`\n- `../data/processed/cu/user_clusters.csv`\n\n**Output:** Modelos entrenados:\n- `../models/crohn/` (global + por cluster)\n- `../models/cu/` (global + por cluster)\n\n**Autor:** Asier Ortiz Garc\u00eda  \n**Fecha:** Noviembre 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udce6 Imports y Configuraci\u00f3n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport json\nimport pickle\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom imblearn.over_sampling import SMOTE\n\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_palette('husl')\nplt.rcParams['figure.figsize'] = (12, 6)\n\n# Crear directorios\nPath('../models/crohn').mkdir(parents=True, exist_ok=True)\nPath('../models/cu').mkdir(parents=True, exist_ok=True)\n\nprint(\"=\" * 80)\nprint(\"MODEL TRAINING: Cluster-Stratified Random Forest\")\nprint(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd27 Funciones de Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_cluster_stratified_models(ibd_type='crohn'):\n    \"\"\"\n    Entrena modelos global + cluster-specific para un tipo de IBD.\n    \"\"\"\n    print(f\"\\n{'='*80}\")\n    print(f\"ENTRENANDO MODELOS: {ibd_type.upper()}\")\n    print(f\"{'='*80}\\n\")\n    \n    # Cargar dataset\n    df = pd.read_csv(f'../data/processed/{ibd_type}/ml_dataset_enhanced.csv')\n    clusters_df = pd.read_csv(f'../data/processed/{ibd_type}/user_clusters.csv')\n    \n    df = df.merge(clusters_df[['user_id', 'cluster']], on='user_id', how='left')\n    \n    print(f\"\u2713 Dataset cargado: {len(df):,} registros\")\n    print(f\"  Usuarios: {df['user_id'].nunique():,}\")\n    print(f\"  Distribuci\u00f3n de clusters: {df['cluster'].value_counts().to_dict()}\")\n    print(f\"  Distribuci\u00f3n de risk: {df['risk_level'].value_counts().to_dict()}\")\n    \n    # Features\n    exclude_cols = ['user_id', 'checkin_date', 'risk_level', 'severity_score', 'cluster',\n                    'sex', 'first_checkin', 'days_since_first_checkin', 'is_flare_day',\n                    'cumulative_flare_days', 'is_bad_day', 'risk_numeric']\n    \n    feature_cols = [col for col in df.columns if col not in exclude_cols]\n    X = df[feature_cols].copy()\n    y = df['risk_level'].copy()\n    \n    # Encode categorical\n    if 'gender' in X.columns:\n        X = pd.get_dummies(X, columns=['gender'], drop_first=True)\n    \n    # Fill missing\n    for col in X.columns:\n        if X[col].dtype in ['float64', 'int64']:\n            X[col].fillna(X[col].median(), inplace=True)\n    \n    print(f\"\\nFeatures: {len(X.columns)}\")\n    \n    # 1. Entrenar modelo global\n    print(f\"\\n1\ufe0f\u20e3 Entrenando modelo GLOBAL...\")\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n    \n    # SMOTE\n    print(\"  Aplicando SMOTE...\")\n    smote = SMOTE(sampling_strategy='not majority', random_state=42)\n    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n    print(f\"  Antes SMOTE: {len(X_train):,} | Despu\u00e9s SMOTE: {len(X_train_res):,}\")\n    \n    # Train\n    rf_global = RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_split=10, random_state=42, n_jobs=-1)\n    rf_global.fit(X_train_res, y_train_res)\n    \n    # Evaluate\n    y_pred = rf_global.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    print(f\"\\n\u2705 Modelo global entrenado - Accuracy: {acc:.3f}\")\n    print(\"\\nClassification Report:\")\n    print(classification_report(y_test, y_pred))\n    \n    # Save global\n    model_path = f'../models/{ibd_type}/rf_severity_classifier_global.pkl'\n    with open(model_path, 'wb') as f:\n        pickle.dump(rf_global, f)\n    print(f\"\ud83d\udcbe Guardado: {model_path}\")\n    \n    # 2. Entrenar modelos por cluster\n    cluster_models = {}\n    n_clusters = df['cluster'].nunique()\n    \n    for cluster_id in range(n_clusters):\n        print(f\"\\n2\ufe0f\u20e3 Entrenando modelo CLUSTER {cluster_id}...\")\n        df_cluster = df[df['cluster'] == cluster_id].copy()\n        \n        if len(df_cluster) < 50:\n            print(f\"  \u26a0\ufe0f  Muy pocos datos ({len(df_cluster)} registros), usando modelo global\")\n            cluster_models[cluster_id] = rf_global\n            continue\n        \n        X_c = df_cluster[feature_cols].copy()\n        y_c = df_cluster['risk_level'].copy()\n        \n        if 'gender' in X_c.columns:\n            X_c = pd.get_dummies(X_c, columns=['gender'], drop_first=True)\n        \n        for col in X_c.columns:\n            if X_c[col].dtype in ['float64', 'int64']:\n                X_c[col].fillna(X_c[col].median(), inplace=True)\n        \n        # Align with global features\n        for col in X.columns:\n            if col not in X_c.columns:\n                X_c[col] = 0\n        X_c = X_c[X.columns]\n        \n        X_train_c, X_test_c, y_train_c, y_test_c = train_test_split(X_c, y_c, test_size=0.2, random_state=42)\n        \n        # SMOTE if enough samples\n        if len(X_train_c) > 30:\n            try:\n                smote_c = SMOTE(sampling_strategy='not majority', random_state=42)\n                X_train_c, y_train_c = smote_c.fit_resample(X_train_c, y_train_c)\n            except:\n                print(\"  \u26a0\ufe0f  SMOTE failed, using original data\")\n        \n        rf_cluster = RandomForestClassifier(n_estimators=150, max_depth=12, random_state=42, n_jobs=-1)\n        rf_cluster.fit(X_train_c, y_train_c)\n        \n        y_pred_c = rf_cluster.predict(X_test_c)\n        acc_c = accuracy_score(y_test_c, y_pred_c)\n        print(f\"  \u2705 Cluster {cluster_id} - Accuracy: {acc_c:.3f}\")\n        \n        cluster_models[cluster_id] = rf_cluster\n        \n        # Save\n        model_path = f'../models/{ibd_type}/rf_severity_classifier_cluster_{cluster_id}.pkl'\n        with open(model_path, 'wb') as f:\n            pickle.dump(rf_cluster, f)\n        print(f\"  \ud83d\udcbe Guardado: {model_path}\")\n    \n    # Metadata\n    metadata = {\n        'ibd_type': ibd_type,\n        'n_clusters': n_clusters,\n        'n_samples': len(df),\n        'n_features': len(X.columns),\n        'features': list(X.columns),\n        'global_accuracy': float(acc),\n        'cluster_models': {f'cluster_{i}': f'rf_severity_classifier_cluster_{i}.pkl' for i in range(n_clusters)}\n    }\n    \n    with open(f'../models/{ibd_type}/cluster_models_metadata.json', 'w') as f:\n        json.dump(metadata, f, indent=2)\n    \n    print(f\"\\n\u2705 {ibd_type.upper()} completado!\")\n    return rf_global, cluster_models, metadata\n\nprint(\"\u2713 Funci\u00f3n de entrenamiento definida\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd04 Entrenar Crohn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_crohn_global, crohn_cluster_models, crohn_metadata = train_cluster_stratified_models('crohn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd04 Entrenar Colitis Ulcerosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_cu_global, cu_cluster_models, cu_metadata = train_cluster_stratified_models('cu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \u2705 Resumen Final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\nprint(\"RESUMEN FINAL\")\nprint(\"=\"*80)\n\nprint(f\"\\n\ud83d\udcca CROHN:\")\nprint(f\"  Modelos entrenados: 1 global + {crohn_metadata['n_clusters']} cluster-specific\")\nprint(f\"  Global accuracy: {crohn_metadata['global_accuracy']:.3f}\")\nprint(f\"  Features: {crohn_metadata['n_features']}\")\n\nprint(f\"\\n\ud83d\udcca CU:\")\nprint(f\"  Modelos entrenados: 1 global + {cu_metadata['n_clusters']} cluster-specific\")\nprint(f\"  Global accuracy: {cu_metadata['global_accuracy']:.3f}\")\nprint(f\"  Features: {cu_metadata['n_features']}\")\n\nprint(\"\\n\ud83d\udcc2 Archivos generados:\")\nprint(f\"  - ../models/crohn/ ({1 + crohn_metadata['n_clusters']} modelos)\")\nprint(f\"  - ../models/cu/ ({1 + cu_metadata['n_clusters']} modelos)\")\nprint(\"  - Metadata JSON files\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\u2705 MODEL TRAINING COMPLETADO\")\nprint(\"=\"*80)\nprint(\"\\nModelos listos para predicci\u00f3n via API!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# \ud83c\udfaf Model Training: Validaci\u00f3n Rigurosa SIN Data Leakage\n\n**Objetivo:** Entrenar modelos con validaci\u00f3n cruzada y m\u00e9tricas reales\n\n**Mejoras:**\n- \u2705 Features corregidas (sin data leakage)\n- \u2705 Cross-validation (StratifiedKFold)\n- \u2705 Confusion matrices\n- \u2705 Feature importance\n- \u2705 Learning curves\n- \u2705 ROC curves (multiclass)\n- \u2705 Comparaci\u00f3n antes/despu\u00e9s\n\n**Autor:** Asier Ortiz Garc\u00eda  \n**Fecha:** Noviembre 2025"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udce6 Imports y Configuraci\u00f3n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pathlib import Path\nimport json\nimport pickle\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, learning_curve\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import (\n    classification_report, confusion_matrix, accuracy_score,\n    f1_score, precision_score, recall_score, roc_auc_score, roc_curve\n)\nfrom sklearn.preprocessing import label_binarize\nfrom imblearn.over_sampling import SMOTE\n\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_palette('husl')\nplt.rcParams['figure.figsize'] = (14, 6)\n\nPath('../models/crohn').mkdir(parents=True, exist_ok=True)\nPath('../models/cu').mkdir(parents=True, exist_ok=True)\nPath('../docs/figures').mkdir(parents=True, exist_ok=True)\n\nprint(\"=\" * 80)\nprint(\"MODEL TRAINING: Cross-Validation + Diagn\u00f3sticos\")\nprint(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd27 Funciones de Visualizaci\u00f3n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(y_true, y_pred, title, save_path=None):\n    \"\"\"Plot confusion matrix.\"\"\"\n    cm = confusion_matrix(y_true, y_pred, labels=['low', 'medium', 'high'])\n    \n    fig, ax = plt.subplots(figsize=(8, 6))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n                xticklabels=['Low', 'Medium', 'High'],\n                yticklabels=['Low', 'Medium', 'High'],\n                ax=ax, cbar_kws={'label': 'Count'})\n    ax.set_title(title, fontsize=14, fontweight='bold')\n    ax.set_ylabel('True Label', fontsize=12)\n    ax.set_xlabel('Predicted Label', fontsize=12)\n    \n    # Add percentages\n    total = cm.sum()\n    for i in range(3):\n        for j in range(3):\n            pct = cm[i, j] / total * 100\n            ax.text(j+0.5, i+0.7, f'({pct:.1f}%)', \n                   ha='center', va='center', fontsize=9, color='gray')\n    \n    plt.tight_layout()\n    if save_path:\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.show()\n\ndef plot_feature_importance(model, feature_names, title, save_path=None, top_n=20):\n    \"\"\"Plot feature importance.\"\"\"\n    importances = model.feature_importances_\n    indices = np.argsort(importances)[::-1][:top_n]\n    \n    fig, ax = plt.subplots(figsize=(10, 8))\n    ax.barh(range(top_n), importances[indices], color='steelblue', edgecolor='black')\n    ax.set_yticks(range(top_n))\n    ax.set_yticklabels([feature_names[i] for i in indices])\n    ax.invert_yaxis()\n    ax.set_xlabel('Importance', fontsize=12)\n    ax.set_title(title, fontsize=14, fontweight='bold')\n    ax.grid(True, alpha=0.3, axis='x')\n    \n    plt.tight_layout()\n    if save_path:\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.show()\n\ndef plot_learning_curves(model, X, y, title, save_path=None):\n    \"\"\"Plot learning curves to detect overfitting.\"\"\"\n    train_sizes, train_scores, val_scores = learning_curve(\n        model, X, y, cv=5, n_jobs=-1,\n        train_sizes=np.linspace(0.1, 1.0, 10),\n        scoring='accuracy', random_state=42\n    )\n    \n    train_mean = train_scores.mean(axis=1)\n    train_std = train_scores.std(axis=1)\n    val_mean = val_scores.mean(axis=1)\n    val_std = val_scores.std(axis=1)\n    \n    fig, ax = plt.subplots(figsize=(10, 6))\n    ax.plot(train_sizes, train_mean, 'o-', color='blue', label='Training score')\n    ax.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n    ax.plot(train_sizes, val_mean, 'o-', color='red', label='Cross-validation score')\n    ax.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='red')\n    \n    ax.set_xlabel('Training Size', fontsize=12)\n    ax.set_ylabel('Accuracy', fontsize=12)\n    ax.set_title(title, fontsize=14, fontweight='bold')\n    ax.legend(loc='best')\n    ax.grid(True, alpha=0.3)\n    \n    # Add gap indicator\n    gap = train_mean[-1] - val_mean[-1]\n    ax.text(0.5, 0.05, f'Train-Val Gap: {gap:.3f}', \n            transform=ax.transAxes, fontsize=11,\n            bbox=dict(boxstyle='round', facecolor='yellow' if gap > 0.1 else 'lightgreen', alpha=0.5))\n    \n    plt.tight_layout()\n    if save_path:\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.show()\n\ndef plot_roc_curves(y_true, y_pred_proba, title, save_path=None):\n    \"\"\"Plot ROC curves for multiclass (one-vs-rest).\"\"\"\n    classes = ['low', 'medium', 'high']\n    y_true_bin = label_binarize(y_true, classes=classes)\n    \n    fig, ax = plt.subplots(figsize=(10, 8))\n    \n    for i, class_name in enumerate(classes):\n        fpr, tpr, _ = roc_curve(y_true_bin[:, i], y_pred_proba[:, i])\n        auc = roc_auc_score(y_true_bin[:, i], y_pred_proba[:, i])\n        ax.plot(fpr, tpr, label=f'{class_name.capitalize()} (AUC = {auc:.3f})', linewidth=2)\n    \n    ax.plot([0, 1], [0, 1], 'k--', label='Random (AUC = 0.500)')\n    ax.set_xlabel('False Positive Rate', fontsize=12)\n    ax.set_ylabel('True Positive Rate', fontsize=12)\n    ax.set_title(title, fontsize=14, fontweight='bold')\n    ax.legend(loc='lower right')\n    ax.grid(True, alpha=0.3)\n    \n    plt.tight_layout()\n    if save_path:\n        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n    plt.show()\n\nprint(\"\u2713 Funciones de visualizaci\u00f3n definidas\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd27 Funci\u00f3n de Entrenamiento con Validaci\u00f3n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_with_cv(ibd_type='crohn'):\n    \"\"\"\n    Entrena modelos con cross-validation y genera diagn\u00f3sticos completos.\n    \"\"\"\n    print(f\"\\n{'='*80}\")\n    print(f\"ENTRENANDO: {ibd_type.upper()} (CON CROSS-VALIDATION)\")\n    print(f\"{'='*80}\\n\")\n    \n    # Cargar dataset\n    df = pd.read_csv(f'../data/processed/{ibd_type}/ml_dataset_enhanced.csv')\n    clusters_df = pd.read_csv(f'../data/processed/{ibd_type}/user_clusters.csv', index_col=0)\n    \n    df = df.merge(clusters_df[['cluster']], left_on='user_id', right_index=True, how='left')\n    \n    print(f\"\u2713 Dataset cargado: {len(df):,} registros\")\n    print(f\"  Usuarios: {df['user_id'].nunique():,}\")\n    print(f\"  Distribuci\u00f3n de risk: {df['risk_level'].value_counts().to_dict()}\")\n    \n    # Features (ELIMINANDO las que causan data leakage)\n    exclude_cols = [\n        'user_id', 'checkin_date', 'risk_level', 'severity_score', 'cluster',\n        'sex', 'first_checkin', 'days_since_first_checkin', 'is_flare_day',\n        'cumulative_flare_days', 'risk_numeric',\n        # Eliminadas por data leakage:\n        'total_symptom_score', 'gi_score', 'systemic_score', 'symptom_severity_category',\n        'symptom_volatility_7d', 'symptom_change_rate', 'is_bad_day', 'days_since_low_symptoms',\n        'vulnerable_state', 'gi_dominant'\n    ]\n    \n    feature_cols = [col for col in df.columns if col not in exclude_cols]\n    X = df[feature_cols].copy()\n    y = df['risk_level'].copy()\n    \n    # Encode categorical\n    if 'gender' in X.columns:\n        X = pd.get_dummies(X, columns=['gender'], drop_first=True)\n    \n    # Fill missing\n    for col in X.columns:\n        if X[col].dtype in ['float64', 'int64']:\n            X[col].fillna(X[col].median(), inplace=True)\n    \n    print(f\"\\n\u2705 Features limpias (sin data leakage): {len(X.columns)}\")\n    print(f\"  Features: {list(X.columns)}\")\n    \n    # Split\n    X_train, X_test, y_train, y_test = train_test_split(\n        X, y, test_size=0.2, random_state=42, stratify=y\n    )\n    \n    # SMOTE\n    print(f\"\\n\ud83d\udd04 Aplicando SMOTE...\")\n    smote = SMOTE(sampling_strategy='not majority', random_state=42)\n    X_train_res, y_train_res = smote.fit_resample(X_train, y_train)\n    print(f\"  Antes: {len(X_train):,} | Despu\u00e9s: {len(X_train_res):,}\")\n    \n    # 1. CROSS-VALIDATION\n    print(f\"\\n1\ufe0f\u20e3  CROSS-VALIDATION (5-fold StratifiedKFold)...\")\n    rf_model = RandomForestClassifier(\n        n_estimators=200, max_depth=15, min_samples_split=10,\n        random_state=42, n_jobs=-1\n    )\n    \n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n    cv_scores = cross_val_score(rf_model, X_train_res, y_train_res, cv=cv, scoring='accuracy', n_jobs=-1)\n    \n    print(f\"\\n  CV Accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std():.3f})\")\n    print(f\"  CV Scores: {[f'{s:.3f}' for s in cv_scores]}\")\n    \n    # 2. TRAIN FINAL MODEL\n    print(f\"\\n2\ufe0f\u20e3  Entrenando modelo final...\")\n    rf_model.fit(X_train_res, y_train_res)\n    \n    # 3. EVALUATE\n    y_pred = rf_model.predict(X_test)\n    y_pred_proba = rf_model.predict_proba(X_test)\n    \n    test_acc = accuracy_score(y_test, y_pred)\n    test_f1 = f1_score(y_test, y_pred, average='weighted')\n    \n    print(f\"\\n\u2705 M\u00c9TRICAS DE TEST:\")\n    print(f\"  Accuracy: {test_acc:.3f}\")\n    print(f\"  F1-score (weighted): {test_f1:.3f}\")\n    print(f\"  Gap (CV vs Test): {abs(cv_scores.mean() - test_acc):.3f}\")\n    \n    if abs(cv_scores.mean() - test_acc) > 0.1:\n        print(f\"  \u26a0\ufe0f  WARNING: Gap > 0.1 indica posible overfitting!\")\n    else:\n        print(f\"  \u2705 Gap < 0.1: Modelo generaliza bien\")\n    \n    print(f\"\\n\ud83d\udcca Classification Report:\")\n    print(classification_report(y_test, y_pred, zero_division=0))\n    \n    # 4. GR\u00c1FICOS DE DIAGN\u00d3STICO\n    print(f\"\\n4\ufe0f\u20e3  Generando gr\u00e1ficos de diagn\u00f3stico...\")\n    \n    # Confusion Matrix\n    plot_confusion_matrix(\n        y_test, y_pred,\n        f'Confusion Matrix - {ibd_type.upper()}',\n        f'../docs/figures/{ibd_type}_confusion_matrix.png'\n    )\n    \n    # Feature Importance\n    plot_feature_importance(\n        rf_model, X.columns,\n        f'Feature Importance - {ibd_type.upper()}',\n        f'../docs/figures/{ibd_type}_feature_importance.png'\n    )\n    \n    # Learning Curves\n    plot_learning_curves(\n        rf_model, X_train_res, y_train_res,\n        f'Learning Curves - {ibd_type.upper()}',\n        f'../docs/figures/{ibd_type}_learning_curves.png'\n    )\n    \n    # ROC Curves\n    plot_roc_curves(\n        y_test, y_pred_proba,\n        f'ROC Curves (One-vs-Rest) - {ibd_type.upper()}',\n        f'../docs/figures/{ibd_type}_roc_curves.png'\n    )\n    \n    # 5. SAVE MODEL\n    model_path = f'../models/{ibd_type}/rf_severity_classifier_global.pkl'\n    with open(model_path, 'wb') as f:\n        pickle.dump(rf_model, f)\n    print(f\"\\n\ud83d\udcbe Modelo guardado: {model_path}\")\n    \n    # Metadata\n    metadata = {\n        'ibd_type': ibd_type,\n        'n_samples': len(df),\n        'n_features': len(X.columns),\n        'features': list(X.columns),\n        'cv_accuracy_mean': float(cv_scores.mean()),\n        'cv_accuracy_std': float(cv_scores.std()),\n        'test_accuracy': float(test_acc),\n        'test_f1_weighted': float(test_f1),\n        'gap_cv_test': float(abs(cv_scores.mean() - test_acc)),\n        'data_leakage_fixed': True\n    }\n    \n    with open(f'../models/{ibd_type}/model_metadata.json', 'w') as f:\n        json.dump(metadata, f, indent=2)\n    \n    print(f\"\u2705 {ibd_type.upper()} completado!\\n\")\n    return rf_model, metadata\n\nprint(\"\u2713 Funci\u00f3n de entrenamiento definida\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd04 Entrenar Crohn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_crohn, crohn_meta = train_with_cv('crohn')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udd04 Entrenar Colitis Ulcerosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf_cu, cu_meta = train_with_cv('cu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## \ud83d\udcca Comparaci\u00f3n Final: Antes vs Despu\u00e9s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\nprint(\"COMPARACI\u00d3N: ANTES vs DESPU\u00c9S (Data Leakage Fix)\")\nprint(\"=\"*80)\n\ncomparison = pd.DataFrame({\n    'Metric': ['Accuracy', 'Features', 'Data Leakage', 'CV Gap', 'Interpretabilidad'],\n    'ANTES (con leakage)': ['99.5%', '34', 'S\u00cd \u26a0\ufe0f', 'N/A', 'Baja'],\n    'DESPU\u00c9S (sin leakage)': [\n        f\"{crohn_meta['test_accuracy']:.1%}\",\n        str(crohn_meta['n_features']),\n        'NO \u2705',\n        f\"{crohn_meta['gap_cv_test']:.3f}\",\n        'Alta'\n    ]\n})\n\nprint(\"\\n\ud83d\udcca CROHN:\")\nprint(comparison.to_string(index=False))\n\nprint(f\"\\n\u2705 Accuracy realista: {crohn_meta['test_accuracy']:.1%}\")\nprint(f\"\u2705 CV Score: {crohn_meta['cv_accuracy_mean']:.3f} (+/- {crohn_meta['cv_accuracy_std']:.3f})\")\nprint(f\"\u2705 Gap CV-Test: {crohn_meta['gap_cv_test']:.3f}\")\n\nif crohn_meta['test_accuracy'] < 0.95:\n    print(\"\\n\ud83c\udfaf \u00c9XITO: Accuracy < 95% indica modelo realista sin data leakage!\")\nelse:\n    print(\"\\n\u26a0\ufe0f  WARNING: Accuracy todav\u00eda muy alta, revisar features\")\n\nprint(\"\\n\ud83d\udcc2 Gr\u00e1ficos generados:\")\nprint(\"  - ../docs/figures/crohn_confusion_matrix.png\")\nprint(\"  - ../docs/figures/crohn_feature_importance.png\")\nprint(\"  - ../docs/figures/crohn_learning_curves.png\")\nprint(\"  - ../docs/figures/crohn_roc_curves.png\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\u2705 ENTRENAMIENTO COMPLETADO - MODELOS VALIDADOS\")\nprint(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
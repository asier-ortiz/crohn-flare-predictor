{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Cluster-Stratified Model Training\n",
    "\n",
    "**Objetivo:** Entrenar modelos especÃ­ficos por cluster de fenotipo y comparar con modelo global\n",
    "\n",
    "**HipÃ³tesis:** Los modelos estratificados por cluster (fenotipo de paciente) mejorarÃ¡n las predicciones\n",
    "\n",
    "**Plan:**\n",
    "1. Cargar datos: ml_dataset.csv + user_clusters.csv\n",
    "2. Entrenar 3 modelos RF (uno por cluster) con SMOTE Moderado\n",
    "3. Comparar mÃ©tricas: Global vs Cluster-Specific\n",
    "4. Guardar: 3 modelos RF + KMeans scaler para inferencia\n",
    "\n",
    "**Autor:** Claude Assistant + Asier Ortiz GarcÃ­a  \n",
    "**Fecha:** Noviembre 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“¦ Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import json\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    f1_score, precision_score, recall_score, accuracy_score\n",
    ")\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "%matplotlib inline\n",
    "\n",
    "# Crear directorios\n",
    "Path('../models').mkdir(exist_ok=True)\n",
    "Path('../docs/figures').mkdir(exist_ok=True)\n",
    "Path('../reports').mkdir(exist_ok=True)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CLUSTER-STRATIFIED MODEL TRAINING\")\n",
    "print(\"Entrenamiento de modelos especÃ­ficos por fenotipo de paciente\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset ML (del notebook 02)\n",
    "df_ml = pd.read_csv('../data/processed/ml_dataset.csv')\n",
    "print(f\"âœ“ ML Dataset: {len(df_ml):,} registros\")\n",
    "\n",
    "# Cargar clusters de usuarios (del notebook 01)\n",
    "df_clusters = pd.read_csv('../data/processed/user_clusters.csv', index_col=0)\n",
    "print(f\"âœ“ User Clusters: {len(df_clusters):,} usuarios con cluster asignado\")\n",
    "\n",
    "# Cargar metadata\n",
    "with open('../data/processed/ml_dataset_metadata.json', 'r') as f:\n",
    "    metadata = json.load(f)\n",
    "\n",
    "feature_cols = metadata['features']\n",
    "target_col = metadata['target']\n",
    "\n",
    "print(f\"\\nðŸ“‹ Features: {len(feature_cols)}\")\n",
    "print(f\"ðŸ“‹ Target: {target_col}\")\n",
    "print(f\"\\n{feature_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Merge Clusters con ML Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets por user_id\n",
    "df = df_ml.merge(df_clusters[['cluster']], left_on='user_id', right_index=True, how='inner')\n",
    "\n",
    "print(f\"Dataset combinado: {len(df):,} registros\")\n",
    "print(f\"\\nDistribuciÃ³n de clusters:\")\n",
    "cluster_dist = df['cluster'].value_counts().sort_index()\n",
    "for cluster_id, count in cluster_dist.items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"  Cluster {cluster_id}: {count:6,} ({pct:5.1f}%)\")\n",
    "\n",
    "print(f\"\\nDistribuciÃ³n de risk_level:\")\n",
    "risk_dist = df['risk_level'].value_counts()\n",
    "for risk, count in risk_dist.items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"  {risk.upper():8} {count:6,} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ AnÃ¡lisis: DistribuciÃ³n de Risk Level por Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla cruzada\n",
    "cross_tab = pd.crosstab(df['cluster'], df['risk_level'], normalize='index') * 100\n",
    "print(\"\\nðŸ“Š DistribuciÃ³n de Risk Level por Cluster (%):\\n\")\n",
    "print(cross_tab.round(1))\n",
    "\n",
    "# Visualizar\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "cross_tab.plot(kind='bar', ax=ax, color=['green', 'orange', 'red'], alpha=0.7)\n",
    "ax.set_title('DistribuciÃ³n de Risk Level por Cluster', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Cluster')\n",
    "ax.set_ylabel('Porcentaje (%)')\n",
    "ax.legend(title='Risk Level', labels=['Low', 'Medium', 'High'])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/figures/risk_by_cluster.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ’¡ ObservaciÃ³n: Si los clusters muestran diferentes distribuciones de risk,\")\n",
    "print(\"   los modelos estratificados podrÃ­an aprender patrones especÃ­ficos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Preparar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode gender\n",
    "gender_map = {'M': 1, 'F': 2, 'O': 0}\n",
    "df['gender'] = df['gender'].map(gender_map)\n",
    "\n",
    "# Separar features y target\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "clusters = df['cluster'].copy()\n",
    "\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(f\"Clusters: {clusters.shape}\")\n",
    "\n",
    "# Verificar valores faltantes\n",
    "missing = X.isnull().sum().sum()\n",
    "if missing > 0:\n",
    "    print(f\"\\nâš ï¸  {missing} valores faltantes - imputando con mediana...\")\n",
    "    X.fillna(X.median(), inplace=True)\n",
    "else:\n",
    "    print(f\"\\nâœ“ Sin valores faltantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Train/Test Split (Estratificado por risk_level Y cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear stratification key (risk_level + cluster)\n",
    "stratify_key = y.astype(str) + '_' + clusters.astype(str)\n",
    "\n",
    "X_train, X_test, y_train, y_test, clusters_train, clusters_test = train_test_split(\n",
    "    X, y, clusters,\n",
    "    test_size=0.2,\n",
    "    stratify=stratify_key,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train set: {len(X_train):,} samples\")\n",
    "print(f\"Test set:  {len(X_test):,} samples\")\n",
    "\n",
    "print(f\"\\nDistribuciÃ³n de clusters en Train:\")\n",
    "for cluster_id in sorted(clusters_train.unique()):\n",
    "    count = (clusters_train == cluster_id).sum()\n",
    "    pct = count / len(clusters_train) * 100\n",
    "    print(f\"  Cluster {cluster_id}: {count:5,} ({pct:5.1f}%)\")\n",
    "\n",
    "print(f\"\\nDistribuciÃ³n de clusters en Test:\")\n",
    "for cluster_id in sorted(clusters_test.unique()):\n",
    "    count = (clusters_test == cluster_id).sum()\n",
    "    pct = count / len(clusters_test) * 100\n",
    "    print(f\"  Cluster {cluster_id}: {count:5,} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Entrenar Modelo Global (Baseline)\n",
    "\n",
    "Primero entrenamos el modelo global como baseline para comparaciÃ³n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŒ² MODELO GLOBAL (Baseline)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# SMOTE Moderado (igual que notebook 03)\n",
    "train_counts = Counter(y_train)\n",
    "total_train = len(y_train)\n",
    "target_high = int(total_train * 0.15)\n",
    "target_medium = int(total_train * 0.35)\n",
    "\n",
    "smote_mod = SMOTE(\n",
    "    sampling_strategy={'high': target_high, 'medium': target_medium},\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Aplicando SMOTE Moderado...\")\n",
    "X_train_smote, y_train_smote = smote_mod.fit_resample(X_train, y_train)\n",
    "\n",
    "smote_counts = Counter(y_train_smote)\n",
    "print(f\"DistribuciÃ³n despuÃ©s de SMOTE:\")\n",
    "for cls in ['low', 'medium', 'high']:\n",
    "    count = smote_counts[cls]\n",
    "    pct = count / len(y_train_smote) * 100\n",
    "    print(f\"  {cls.upper():8} {count:5,} ({pct:5.1f}%)\")\n",
    "\n",
    "# Entrenar modelo global\n",
    "model_global = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nEntrenando modelo global...\")\n",
    "model_global.fit(X_train_smote, y_train_smote)\n",
    "print(\"âœ“ Entrenamiento completado\")\n",
    "\n",
    "# Evaluar\n",
    "y_pred_global = model_global.predict(X_test)\n",
    "\n",
    "print(\"\\nðŸ“Š MÃ©tricas del Modelo Global:\\n\")\n",
    "print(classification_report(y_test, y_pred_global, \n",
    "                          target_names=['low', 'medium', 'high'],\n",
    "                          digits=3))\n",
    "\n",
    "# Guardar mÃ©tricas globales para comparaciÃ³n\n",
    "global_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_global),\n",
    "    'f1_macro': f1_score(y_test, y_pred_global, average='macro'),\n",
    "    'f1_low': f1_score(y_test, y_pred_global, labels=['low'], average='macro'),\n",
    "    'f1_medium': f1_score(y_test, y_pred_global, labels=['medium'], average='macro'),\n",
    "    'f1_high': f1_score(y_test, y_pred_global, labels=['high'], average='macro'),\n",
    "    'recall_high': recall_score(y_test, y_pred_global, labels=['high'], average='macro'),\n",
    "    'precision_high': precision_score(y_test, y_pred_global, labels=['high'], average='macro')\n",
    "}\n",
    "\n",
    "print(f\"\\nðŸ“ˆ MÃ©tricas clave:\")\n",
    "print(f\"  Accuracy:      {global_metrics['accuracy']:.3f}\")\n",
    "print(f\"  F1 Macro:      {global_metrics['f1_macro']:.3f}\")\n",
    "print(f\"  F1 High:       {global_metrics['f1_high']:.3f}\")\n",
    "print(f\"  Recall High:   {global_metrics['recall_high']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Entrenar Modelos por Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŽ¯ MODELOS ESTRATIFICADOS POR CLUSTER\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "cluster_models = {}\n",
    "cluster_metrics = {}\n",
    "cluster_predictions = {}\n",
    "\n",
    "for cluster_id in sorted(clusters_train.unique()):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ðŸ”¬ CLUSTER {cluster_id}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Filtrar datos del cluster\n",
    "    train_mask = clusters_train == cluster_id\n",
    "    test_mask = clusters_test == cluster_id\n",
    "    \n",
    "    X_train_cluster = X_train[train_mask]\n",
    "    y_train_cluster = y_train[train_mask]\n",
    "    X_test_cluster = X_test[test_mask]\n",
    "    y_test_cluster = y_test[test_mask]\n",
    "    \n",
    "    print(f\"Train samples: {len(X_train_cluster):,}\")\n",
    "    print(f\"Test samples:  {len(X_test_cluster):,}\")\n",
    "    \n",
    "    # DistribuciÃ³n de clases\n",
    "    print(f\"\\nDistribuciÃ³n de clases (train):\")\n",
    "    train_dist = Counter(y_train_cluster)\n",
    "    for cls in ['low', 'medium', 'high']:\n",
    "        count = train_dist.get(cls, 0)\n",
    "        pct = count / len(y_train_cluster) * 100 if len(y_train_cluster) > 0 else 0\n",
    "        print(f\"  {cls.upper():8} {count:5,} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # SMOTE si hay suficientes muestras\n",
    "    if len(X_train_cluster) >= 50 and len(train_dist) >= 2:\n",
    "        try:\n",
    "            # Ajustar targets de SMOTE segÃºn tamaÃ±o del cluster\n",
    "            cluster_total = len(y_train_cluster)\n",
    "            cluster_high = int(cluster_total * 0.15)\n",
    "            cluster_medium = int(cluster_total * 0.35)\n",
    "            \n",
    "            # Solo aplicar SMOTE si hay al menos 2 muestras de cada clase minoritaria\n",
    "            min_samples = min([v for k, v in train_dist.items() if k in ['medium', 'high']])\n",
    "            \n",
    "            if min_samples >= 2:\n",
    "                smote_cluster = SMOTE(\n",
    "                    sampling_strategy={\n",
    "                        'high': max(cluster_high, train_dist.get('high', 0)),\n",
    "                        'medium': max(cluster_medium, train_dist.get('medium', 0))\n",
    "                    },\n",
    "                    random_state=42\n",
    "                )\n",
    "                \n",
    "                print(\"\\nAplicando SMOTE...\")\n",
    "                X_train_cluster_smote, y_train_cluster_smote = smote_cluster.fit_resample(\n",
    "                    X_train_cluster, y_train_cluster\n",
    "                )\n",
    "                \n",
    "                smote_dist = Counter(y_train_cluster_smote)\n",
    "                print(f\"DistribuciÃ³n despuÃ©s de SMOTE:\")\n",
    "                for cls in ['low', 'medium', 'high']:\n",
    "                    count = smote_dist.get(cls, 0)\n",
    "                    pct = count / len(y_train_cluster_smote) * 100\n",
    "                    print(f\"  {cls.upper():8} {count:5,} ({pct:5.1f}%)\")\n",
    "            else:\n",
    "                print(\"\\nâš ï¸  Pocas muestras minoritarias, saltando SMOTE\")\n",
    "                X_train_cluster_smote = X_train_cluster\n",
    "                y_train_cluster_smote = y_train_cluster\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâš ï¸  Error en SMOTE: {e}\")\n",
    "            print(\"   Continuando sin SMOTE...\")\n",
    "            X_train_cluster_smote = X_train_cluster\n",
    "            y_train_cluster_smote = y_train_cluster\n",
    "    else:\n",
    "        print(\"\\nâš ï¸  Cluster pequeÃ±o, entrenando sin SMOTE\")\n",
    "        X_train_cluster_smote = X_train_cluster\n",
    "        y_train_cluster_smote = y_train_cluster\n",
    "    \n",
    "    # Entrenar modelo del cluster\n",
    "    model_cluster = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(\"\\nEntrenando modelo...\")\n",
    "    model_cluster.fit(X_train_cluster_smote, y_train_cluster_smote)\n",
    "    print(\"âœ“ Entrenamiento completado\")\n",
    "    \n",
    "    # Evaluar en test set del cluster\n",
    "    y_pred_cluster = model_cluster.predict(X_test_cluster)\n",
    "    \n",
    "    print(\"\\nðŸ“Š MÃ©tricas del Cluster:\\n\")\n",
    "    print(classification_report(y_test_cluster, y_pred_cluster,\n",
    "                              target_names=['low', 'medium', 'high'],\n",
    "                              digits=3,\n",
    "                              zero_division=0))\n",
    "    \n",
    "    # Guardar mÃ©tricas\n",
    "    cluster_metrics[cluster_id] = {\n",
    "        'accuracy': accuracy_score(y_test_cluster, y_pred_cluster),\n",
    "        'f1_macro': f1_score(y_test_cluster, y_pred_cluster, average='macro', zero_division=0),\n",
    "        'f1_low': f1_score(y_test_cluster, y_pred_cluster, labels=['low'], average='macro', zero_division=0),\n",
    "        'f1_medium': f1_score(y_test_cluster, y_pred_cluster, labels=['medium'], average='macro', zero_division=0),\n",
    "        'f1_high': f1_score(y_test_cluster, y_pred_cluster, labels=['high'], average='macro', zero_division=0),\n",
    "        'recall_high': recall_score(y_test_cluster, y_pred_cluster, labels=['high'], average='macro', zero_division=0),\n",
    "        'precision_high': precision_score(y_test_cluster, y_pred_cluster, labels=['high'], average='macro', zero_division=0),\n",
    "        'n_train': len(X_train_cluster),\n",
    "        'n_test': len(X_test_cluster)\n",
    "    }\n",
    "    \n",
    "    # Guardar modelo y predicciones\n",
    "    cluster_models[cluster_id] = model_cluster\n",
    "    cluster_predictions[cluster_id] = {\n",
    "        'y_true': y_test_cluster,\n",
    "        'y_pred': y_pred_cluster\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nâœ“ Cluster {cluster_id} completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Comparar: Global vs Cluster-Specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ“Š COMPARACIÃ“N: Modelo Global vs Modelos por Cluster\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Calcular mÃ©tricas agregadas de modelos por cluster\n",
    "# (promedio ponderado por tamaÃ±o del cluster)\n",
    "total_test_samples = sum([m['n_test'] for m in cluster_metrics.values()])\n",
    "\n",
    "weighted_cluster_metrics = {\n",
    "    'accuracy': sum([m['accuracy'] * m['n_test'] for m in cluster_metrics.values()]) / total_test_samples,\n",
    "    'f1_macro': sum([m['f1_macro'] * m['n_test'] for m in cluster_metrics.values()]) / total_test_samples,\n",
    "    'f1_low': sum([m['f1_low'] * m['n_test'] for m in cluster_metrics.values()]) / total_test_samples,\n",
    "    'f1_medium': sum([m['f1_medium'] * m['n_test'] for m in cluster_metrics.values()]) / total_test_samples,\n",
    "    'f1_high': sum([m['f1_high'] * m['n_test'] for m in cluster_metrics.values()]) / total_test_samples,\n",
    "    'recall_high': sum([m['recall_high'] * m['n_test'] for m in cluster_metrics.values()]) / total_test_samples,\n",
    "    'precision_high': sum([m['precision_high'] * m['n_test'] for m in cluster_metrics.values()]) / total_test_samples\n",
    "}\n",
    "\n",
    "# Tabla comparativa\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Modelo Global': global_metrics,\n",
    "    'Modelos por Cluster (avg)': weighted_cluster_metrics\n",
    "}).T\n",
    "\n",
    "print(\"\\nðŸ“ˆ MÃ©tricas Comparativas:\\n\")\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Calcular diferencias\n",
    "print(\"\\nðŸ“Š Diferencias (Cluster - Global):\\n\")\n",
    "for metric in comparison_df.columns:\n",
    "    diff = weighted_cluster_metrics[metric] - global_metrics[metric]\n",
    "    pct_change = (diff / global_metrics[metric]) * 100 if global_metrics[metric] > 0 else 0\n",
    "    symbol = 'ðŸ“ˆ' if diff > 0 else 'ðŸ“‰' if diff < 0 else 'âž¡ï¸'\n",
    "    print(f\"  {symbol} {metric:20} {diff:+.4f} ({pct_change:+.2f}%)\")\n",
    "\n",
    "# Visualizar comparaciÃ³n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: F1 Scores por clase\n",
    "metrics_to_plot = ['f1_low', 'f1_medium', 'f1_high']\n",
    "x = np.arange(len(metrics_to_plot))\n",
    "width = 0.35\n",
    "\n",
    "global_vals = [global_metrics[m] for m in metrics_to_plot]\n",
    "cluster_vals = [weighted_cluster_metrics[m] for m in metrics_to_plot]\n",
    "\n",
    "axes[0].bar(x - width/2, global_vals, width, label='Global', alpha=0.8)\n",
    "axes[0].bar(x + width/2, cluster_vals, width, label='Cluster-Specific', alpha=0.8)\n",
    "axes[0].set_xlabel('MÃ©trica')\n",
    "axes[0].set_ylabel('F1-Score')\n",
    "axes[0].set_title('F1-Scores: Global vs Cluster-Specific', fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(['F1 Low', 'F1 Medium', 'F1 High'])\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 2: Accuracy y F1 Macro\n",
    "metrics2 = ['accuracy', 'f1_macro', 'recall_high']\n",
    "x2 = np.arange(len(metrics2))\n",
    "\n",
    "global_vals2 = [global_metrics[m] for m in metrics2]\n",
    "cluster_vals2 = [weighted_cluster_metrics[m] for m in metrics2]\n",
    "\n",
    "axes[1].bar(x2 - width/2, global_vals2, width, label='Global', alpha=0.8)\n",
    "axes[1].bar(x2 + width/2, cluster_vals2, width, label='Cluster-Specific', alpha=0.8)\n",
    "axes[1].set_xlabel('MÃ©trica')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('MÃ©tricas Generales: Global vs Cluster-Specific', fontweight='bold')\n",
    "axes[1].set_xticks(x2)\n",
    "axes[1].set_xticklabels(['Accuracy', 'F1 Macro', 'Recall High'])\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/figures/comparison_global_vs_cluster.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ MÃ©tricas Detalladas por Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla detallada\n",
    "cluster_details = pd.DataFrame(cluster_metrics).T\n",
    "print(\"\\nðŸ“Š MÃ©tricas Detalladas por Cluster:\\n\")\n",
    "print(cluster_details.round(4))\n",
    "\n",
    "# Visualizar mÃ©tricas por cluster\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics_viz = ['accuracy', 'f1_macro', 'f1_high', 'recall_high']\n",
    "titles = ['Accuracy por Cluster', 'F1 Macro por Cluster', \n",
    "          'F1 High por Cluster', 'Recall High por Cluster']\n",
    "\n",
    "for idx, (metric, title) in enumerate(zip(metrics_viz, titles)):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    cluster_ids = list(cluster_details.index)\n",
    "    values = cluster_details[metric].values\n",
    "    \n",
    "    bars = ax.bar(cluster_ids, values, alpha=0.7, color='steelblue')\n",
    "    ax.axhline(y=global_metrics[metric], color='red', linestyle='--', \n",
    "               linewidth=2, label='Global Model', alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Cluster')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Anotar valores\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/figures/metrics_by_cluster.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”Ÿ Entrenar KMeans para Inferencia de Cluster\n",
    "\n",
    "Para la API: necesitamos un modelo KMeans entrenado con las mismas features que usÃ³ el clustering original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸŽ¯ ENTRENAR KMEANS PARA INFERENCIA DE CLUSTER\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Cargar cluster_profiles del notebook 01\n",
    "try:\n",
    "    cluster_profiles = pd.read_csv('../data/processed/cluster_profiles.csv', index_col=0)\n",
    "    print(\"âœ“ Cluster profiles cargados\")\n",
    "    print(cluster_profiles)\n",
    "except FileNotFoundError:\n",
    "    print(\"âš ï¸  cluster_profiles.csv no encontrado\")\n",
    "    print(\"   Creando profiles simplificados desde datos actuales...\\n\")\n",
    "    \n",
    "    # Crear profiles desde datos actuales\n",
    "    symptom_cols = ['abdominal_pain', 'blood_in_stool', 'diarrhea', 'fatigue', 'fever', 'nausea']\n",
    "    cluster_profiles = df.groupby('cluster')[symptom_cols].mean()\n",
    "    print(cluster_profiles)\n",
    "\n",
    "# Features de sÃ­ntomas para clustering (igual que notebook 01)\n",
    "symptom_features = ['abdominal_pain', 'blood_in_stool', 'diarrhea', 'fatigue', 'fever', 'nausea']\n",
    "\n",
    "# Crear features derivadas si estÃ¡n en cluster_profiles\n",
    "if 'pain_diarrhea_ratio' in cluster_profiles.columns:\n",
    "    symptom_features.append('pain_diarrhea_ratio')\n",
    "if 'blood_freq' in cluster_profiles.columns:\n",
    "    symptom_features.append('blood_freq')\n",
    "\n",
    "# Filtrar solo features disponibles\n",
    "available_features = [f for f in symptom_features if f in df.columns]\n",
    "print(f\"\\nFeatures para clustering: {available_features}\")\n",
    "\n",
    "# Preparar datos para KMeans (usar todos los datos con cluster conocido)\n",
    "X_clustering = df[available_features].copy()\n",
    "y_clustering = df['cluster'].copy()\n",
    "\n",
    "# Normalizar (StandardScaler)\n",
    "scaler = StandardScaler()\n",
    "X_clustering_scaled = scaler.fit_transform(X_clustering)\n",
    "\n",
    "print(f\"\\nDatos para KMeans: {X_clustering_scaled.shape}\")\n",
    "\n",
    "# Entrenar KMeans con k=3\n",
    "n_clusters = len(df['cluster'].unique())\n",
    "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=50)\n",
    "\n",
    "print(f\"\\nEntrenando KMeans con k={n_clusters}...\")\n",
    "kmeans.fit(X_clustering_scaled)\n",
    "print(\"âœ“ KMeans entrenado\")\n",
    "\n",
    "# Verificar centroides\n",
    "print(f\"\\nCentroides (escalados):\\n\")\n",
    "centroids_df = pd.DataFrame(\n",
    "    kmeans.cluster_centers_,\n",
    "    columns=available_features,\n",
    "    index=[f'Cluster {i}' for i in range(n_clusters)]\n",
    ")\n",
    "print(centroids_df.round(3))\n",
    "\n",
    "# Guardar scaler y kmeans\n",
    "with open('../models/cluster_scaler.pkl', 'wb') as f:\n",
    "    pickle.dump(scaler, f)\n",
    "print(\"\\nâœ“ Scaler guardado: models/cluster_scaler.pkl\")\n",
    "\n",
    "with open('../models/cluster_kmeans.pkl', 'wb') as f:\n",
    "    pickle.dump(kmeans, f)\n",
    "print(\"âœ“ KMeans guardado: models/cluster_kmeans.pkl\")\n",
    "\n",
    "# Guardar metadata de clustering\n",
    "cluster_metadata = {\n",
    "    'n_clusters': n_clusters,\n",
    "    'features': available_features,\n",
    "    'trained_date': datetime.now().isoformat(),\n",
    "    'n_samples': len(X_clustering)\n",
    "}\n",
    "\n",
    "with open('../models/cluster_metadata.json', 'w') as f:\n",
    "    json.dump(cluster_metadata, f, indent=2)\n",
    "print(\"âœ“ Metadata guardada: models/cluster_metadata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£1ï¸âƒ£ Guardar Modelos por Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ’¾ GUARDANDO MODELOS POR CLUSTER\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for cluster_id, model in cluster_models.items():\n",
    "    model_path = f'../models/rf_severity_classifier_cluster_{cluster_id}.pkl'\n",
    "    \n",
    "    with open(model_path, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "    \n",
    "    size_mb = Path(model_path).stat().st_size / (1024**2)\n",
    "    print(f\"âœ“ Cluster {cluster_id}: {model_path} ({size_mb:.2f} MB)\")\n",
    "\n",
    "# Guardar metadata de modelos por cluster\n",
    "cluster_models_metadata = {\n",
    "    'trained_date': datetime.now().isoformat(),\n",
    "    'n_clusters': len(cluster_models),\n",
    "    'features': feature_cols,\n",
    "    'target': target_col,\n",
    "    'model_type': 'RandomForestClassifier',\n",
    "    'clusters': {}\n",
    "}\n",
    "\n",
    "for cluster_id in cluster_models.keys():\n",
    "    cluster_models_metadata['clusters'][int(cluster_id)] = {\n",
    "        'model_file': f'rf_severity_classifier_cluster_{cluster_id}.pkl',\n",
    "        'metrics': {k: float(v) for k, v in cluster_metrics[cluster_id].items() \n",
    "                   if k not in ['n_train', 'n_test']},\n",
    "        'n_train': int(cluster_metrics[cluster_id]['n_train']),\n",
    "        'n_test': int(cluster_metrics[cluster_id]['n_test'])\n",
    "    }\n",
    "\n",
    "with open('../models/cluster_models_metadata.json', 'w') as f:\n",
    "    json.dump(cluster_models_metadata, f, indent=2)\n",
    "\n",
    "print(\"\\nâœ“ Metadata guardada: models/cluster_models_metadata.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£2ï¸âƒ£ Guardar Reporte Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear reporte completo\n",
    "report = {\n",
    "    'title': 'Cluster-Stratified Model Training Report',\n",
    "    'date': datetime.now().isoformat(),\n",
    "    'global_model': {\n",
    "        'metrics': {k: float(v) for k, v in global_metrics.items()},\n",
    "        'model_file': 'rf_severity_classifier.pkl'\n",
    "    },\n",
    "    'cluster_models': {\n",
    "        'weighted_avg_metrics': {k: float(v) for k, v in weighted_cluster_metrics.items()},\n",
    "        'individual_clusters': cluster_models_metadata['clusters']\n",
    "    },\n",
    "    'comparison': {\n",
    "        'improvements': {},\n",
    "        'recommendation': ''\n",
    "    }\n",
    "}\n",
    "\n",
    "# Calcular mejoras\n",
    "for metric in global_metrics.keys():\n",
    "    diff = weighted_cluster_metrics[metric] - global_metrics[metric]\n",
    "    pct_change = (diff / global_metrics[metric]) * 100 if global_metrics[metric] > 0 else 0\n",
    "    report['comparison']['improvements'][metric] = {\n",
    "        'absolute_diff': float(diff),\n",
    "        'percent_change': float(pct_change),\n",
    "        'improved': bool(diff > 0)\n",
    "    }\n",
    "\n",
    "# RecomendaciÃ³n\n",
    "f1_high_improved = report['comparison']['improvements']['f1_high']['improved']\n",
    "recall_high_improved = report['comparison']['improvements']['recall_high']['improved']\n",
    "\n",
    "if f1_high_improved and recall_high_improved:\n",
    "    report['comparison']['recommendation'] = \"USAR MODELOS POR CLUSTER: Mejoran las mÃ©tricas clave (F1 y Recall de HIGH)\"\n",
    "elif f1_high_improved or recall_high_improved:\n",
    "    report['comparison']['recommendation'] = \"EVALUAR: Mejora parcial en mÃ©tricas clave. Considerar trade-offs.\"\n",
    "else:\n",
    "    report['comparison']['recommendation'] = \"MANTENER MODELO GLOBAL: Los modelos por cluster no mejoran significativamente\"\n",
    "\n",
    "# Guardar reporte\n",
    "report_path = '../reports/cluster_stratified_training_report.json'\n",
    "with open(report_path, 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "print(f\"\\nâœ“ Reporte completo guardado: {report_path}\")\n",
    "\n",
    "# Mostrar recomendaciÃ³n\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ðŸ’¡ RECOMENDACIÃ“N FINAL\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{report['comparison']['recommendation']}\")\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Resumen del Notebook\n",
    "\n",
    "### Lo que hemos logrado:\n",
    "\n",
    "1. âœ… Entrenado **3 modelos RF** (uno por cluster de fenotipo)\n",
    "2. âœ… Comparado mÃ©tricas: **Global vs Cluster-Specific**\n",
    "3. âœ… Guardado modelos por cluster + KMeans + Scaler para inferencia\n",
    "4. âœ… Generado reporte completo con recomendaciÃ³n\n",
    "\n",
    "### Archivos generados:\n",
    "\n",
    "- `models/rf_severity_classifier_cluster_0.pkl` - Modelo Cluster 0\n",
    "- `models/rf_severity_classifier_cluster_1.pkl` - Modelo Cluster 1\n",
    "- `models/rf_severity_classifier_cluster_2.pkl` - Modelo Cluster 2\n",
    "- `models/cluster_kmeans.pkl` - KMeans para inferir cluster de nuevos usuarios\n",
    "- `models/cluster_scaler.pkl` - StandardScaler para normalizar features\n",
    "- `models/cluster_models_metadata.json` - Metadata de modelos\n",
    "- `reports/cluster_stratified_training_report.json` - Reporte completo\n",
    "\n",
    "### PrÃ³ximos pasos:\n",
    "\n",
    "1. **Actualizar API** (`api/ml_model.py`):\n",
    "   - Cargar KMeans y Scaler\n",
    "   - Inferir cluster del usuario\n",
    "   - Usar modelo especÃ­fico del cluster\n",
    "\n",
    "2. **Probar API** con nuevos endpoints\n",
    "\n",
    "3. **Evaluar en producciÃ³n** y monitorear mÃ©tricas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

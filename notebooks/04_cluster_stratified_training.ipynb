{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# \ud83c\udfaf Cluster-Stratified Model Training - CROHN\n\n**Objetivo:** Entrenar modelos espec\u00edficos por cluster de fenotipo para CROHN y comparar con modelo global\n\n**Hip\u00f3tesis:** Los modelos estratificados por cluster (fenotipo de paciente) mejorar\u00e1n las predicciones\n\n**Plan:**\n1. Cargar datos: data/processed/crohn/ml_dataset.csv + user_clusters.csv\n2. Entrenar 3 modelos RF (uno por cluster) con SMOTE Moderado\n3. Comparar m\u00e9tricas: Global vs Cluster-Specific\n4. Guardar: models/crohn/ - 3 modelos RF + KMeans scaler para inferencia\n\n**Autor:** Claude Assistant + Asier Ortiz Garc\u00eda  \n**Fecha:** Noviembre 2025"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udce6 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport json\nimport pickle\nfrom datetime import datetime\nfrom pathlib import Path\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import (\n    classification_report, confusion_matrix, \n    f1_score, precision_score, recall_score, accuracy_score\n)\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\n\nplt.style.use('seaborn-v0_8-whitegrid')\nsns.set_palette('husl')\nplt.rcParams['figure.figsize'] = (14, 6)\n%matplotlib inline\n\n# Crear directorios para Crohn\nPath('../models/crohn').mkdir(parents=True, exist_ok=True)\nPath('../docs/figures').mkdir(parents=True, exist_ok=True)\nPath('../reports').mkdir(parents=True, exist_ok=True)\n\nprint(\"=\" * 80)\nprint(\"CLUSTER-STRATIFIED MODEL TRAINING - CROHN\")\nprint(\"Entrenamiento de modelos espec\u00edficos por fenotipo de paciente\")\nprint(\"=\" * 80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\ufe0f\u20e3 Cargar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cargar dataset ML de Crohn (del notebook 02 V2)\ndf_ml = pd.read_csv('../data/processed/crohn/ml_dataset.csv')\nprint(f\"\u2713 ML Dataset (Crohn): {len(df_ml):,} registros\")\n\n# Cargar clusters de usuarios de Crohn (del notebook 01 V2)\ndf_clusters = pd.read_csv('../data/processed/crohn/user_clusters.csv', index_col=0)\nprint(f\"\u2713 User Clusters (Crohn): {len(df_clusters):,} usuarios con cluster asignado\")\n\n# Cargar metadata\nwith open('../data/processed/crohn/ml_dataset_metadata.json', 'r') as f:\n    metadata = json.load(f)\n\nfeature_cols = metadata['features']\ntarget_col = metadata['target']\n\nprint(f\"\\n\ud83d\udccb Features: {len(feature_cols)}\")\nprint(f\"\ud83d\udccb Target: {target_col}\")\nprint(f\"\\n{feature_cols}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\ufe0f\u20e3 Merge Clusters con ML Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge datasets por user_id\n",
    "df = df_ml.merge(df_clusters[['cluster']], left_on='user_id', right_index=True, how='inner')\n",
    "\n",
    "print(f\"Dataset combinado: {len(df):,} registros\")\n",
    "print(f\"\\nDistribuci\u00f3n de clusters:\")\n",
    "cluster_dist = df['cluster'].value_counts().sort_index()\n",
    "for cluster_id, count in cluster_dist.items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"  Cluster {cluster_id}: {count:6,} ({pct:5.1f}%)\")\n",
    "\n",
    "print(f\"\\nDistribuci\u00f3n de risk_level:\")\n",
    "risk_dist = df['risk_level'].value_counts()\n",
    "for risk, count in risk_dist.items():\n",
    "    pct = count / len(df) * 100\n",
    "    print(f\"  {risk.upper():8} {count:6,} ({pct:5.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\ufe0f\u20e3 An\u00e1lisis: Distribuci\u00f3n de Risk Level por Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tabla cruzada\n",
    "cross_tab = pd.crosstab(df['cluster'], df['risk_level'], normalize='index') * 100\n",
    "print(\"\\n\ud83d\udcca Distribuci\u00f3n de Risk Level por Cluster (%):\\n\")\n",
    "print(cross_tab.round(1))\n",
    "\n",
    "# Visualizar\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "cross_tab.plot(kind='bar', ax=ax, color=['green', 'orange', 'red'], alpha=0.7)\n",
    "ax.set_title('Distribuci\u00f3n de Risk Level por Cluster', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Cluster')\n",
    "ax.set_ylabel('Porcentaje (%)')\n",
    "ax.legend(title='Risk Level', labels=['Low', 'Medium', 'High'])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/figures/risk_by_cluster.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Observaci\u00f3n: Si los clusters muestran diferentes distribuciones de risk,\")\n",
    "print(\"   los modelos estratificados podr\u00edan aprender patrones espec\u00edficos.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\ufe0f\u20e3 Preparar Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode gender\n",
    "gender_map = {'M': 1, 'F': 2, 'O': 0}\n",
    "df['gender'] = df['gender'].map(gender_map)\n",
    "\n",
    "# Separar features y target\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "clusters = df['cluster'].copy()\n",
    "\n",
    "print(f\"Features (X): {X.shape}\")\n",
    "print(f\"Target (y): {y.shape}\")\n",
    "print(f\"Clusters: {clusters.shape}\")\n",
    "\n",
    "# Verificar valores faltantes\n",
    "missing = X.isnull().sum().sum()\n",
    "if missing > 0:\n",
    "    print(f\"\\n\u26a0\ufe0f  {missing} valores faltantes - imputando con mediana...\")\n",
    "    X.fillna(X.median(), inplace=True)\n",
    "else:\n",
    "    print(f\"\\n\u2713 Sin valores faltantes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5\ufe0f\u20e3 Train/Test Split (Estratificado por risk_level Y cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Crear stratification key (risk_level + cluster)\nstratify_key = y.astype(str) + '_' + clusters.astype(str)\n\n# Verificar si hay suficientes muestras para estratificaci\u00f3n\nfrom collections import Counter\nstratify_counts = Counter(stratify_key)\nmin_count = min(stratify_counts.values())\n\nprint(f\"Muestras m\u00ednimas por combinaci\u00f3n risk_level+cluster: {min_count}\")\n\nif min_count < 2:\n    print(\"\u26a0\ufe0f  Algunas combinaciones tienen <2 muestras. Estratificando solo por risk_level...\")\n    stratify_by = y\nelif min_count < 5:\n    print(\"\u26a0\ufe0f  Pocas muestras en algunas combinaciones. Estratificando solo por risk_level...\")\n    stratify_by = y\nelse:\n    print(\"\u2713 Suficientes muestras. Estratificando por risk_level + cluster\")\n    stratify_by = stratify_key\n\nX_train, X_test, y_train, y_test, clusters_train, clusters_test = train_test_split(\n    X, y, clusters,\n    test_size=0.2,\n    stratify=stratify_by,\n    random_state=42\n)\n\nprint(f\"\\nTrain set: {len(X_train):,} samples\")\nprint(f\"Test set:  {len(X_test):,} samples\")\n\nprint(f\"\\nDistribuci\u00f3n de clusters en Train:\")\nfor cluster_id in sorted(clusters_train.unique()):\n    count = (clusters_train == cluster_id).sum()\n    pct = count / len(clusters_train) * 100\n    print(f\"  Cluster {cluster_id}: {count:5,} ({pct:5.1f}%)\")\n\nprint(f\"\\nDistribuci\u00f3n de clusters en Test:\")\nfor cluster_id in sorted(clusters_test.unique()):\n    count = (clusters_test == cluster_id).sum()\n    pct = count / len(clusters_test) * 100\n    print(f\"  Cluster {cluster_id}: {count:5,} ({pct:5.1f}%)\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6\ufe0f\u20e3 Entrenar Modelo Global (Baseline)\n",
    "\n",
    "Primero entrenamos el modelo global como baseline para comparaci\u00f3n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\ud83c\udf32 MODELO GLOBAL (Baseline)\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# SMOTE Moderado (igual que notebook 03)\n",
    "train_counts = Counter(y_train)\n",
    "total_train = len(y_train)\n",
    "target_high = int(total_train * 0.15)\n",
    "target_medium = int(total_train * 0.35)\n",
    "\n",
    "smote_mod = SMOTE(\n",
    "    sampling_strategy={'high': target_high, 'medium': target_medium},\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Aplicando SMOTE Moderado...\")\n",
    "X_train_smote, y_train_smote = smote_mod.fit_resample(X_train, y_train)\n",
    "\n",
    "smote_counts = Counter(y_train_smote)\n",
    "print(f\"Distribuci\u00f3n despu\u00e9s de SMOTE:\")\n",
    "for cls in ['low', 'medium', 'high']:\n",
    "    count = smote_counts[cls]\n",
    "    pct = count / len(y_train_smote) * 100\n",
    "    print(f\"  {cls.upper():8} {count:5,} ({pct:5.1f}%)\")\n",
    "\n",
    "# Entrenar modelo global\n",
    "model_global = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=15,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=4,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "print(\"\\nEntrenando modelo global...\")\n",
    "model_global.fit(X_train_smote, y_train_smote)\n",
    "print(\"\u2713 Entrenamiento completado\")\n",
    "\n",
    "# Evaluar\n",
    "y_pred_global = model_global.predict(X_test)\n",
    "\n",
    "print(\"\\n\ud83d\udcca M\u00e9tricas del Modelo Global:\\n\")\n",
    "print(classification_report(y_test, y_pred_global, \n",
    "                          target_names=['low', 'medium', 'high'],\n",
    "                          digits=3))\n",
    "\n",
    "# Guardar m\u00e9tricas globales para comparaci\u00f3n\n",
    "global_metrics = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred_global),\n",
    "    'f1_macro': f1_score(y_test, y_pred_global, average='macro'),\n",
    "    'f1_low': f1_score(y_test, y_pred_global, labels=['low'], average='macro'),\n",
    "    'f1_medium': f1_score(y_test, y_pred_global, labels=['medium'], average='macro'),\n",
    "    'f1_high': f1_score(y_test, y_pred_global, labels=['high'], average='macro'),\n",
    "    'recall_high': recall_score(y_test, y_pred_global, labels=['high'], average='macro'),\n",
    "    'precision_high': precision_score(y_test, y_pred_global, labels=['high'], average='macro')\n",
    "}\n",
    "\n",
    "print(f\"\\n\ud83d\udcc8 M\u00e9tricas clave:\")\n",
    "print(f\"  Accuracy:      {global_metrics['accuracy']:.3f}\")\n",
    "print(f\"  F1 Macro:      {global_metrics['f1_macro']:.3f}\")\n",
    "print(f\"  F1 High:       {global_metrics['f1_high']:.3f}\")\n",
    "print(f\"  Recall High:   {global_metrics['recall_high']:.3f}\")",
    "\n",
    "# Guardar modelo global\n",
    "global_model_path = '../models/crohn/rf_severity_classifier_global.pkl'\n",
    "with open(global_model_path, 'wb') as f:\n",
    "    pickle.dump(model_global, f)\n",
    "print(f\"\\n\ud83d\udcbe Modelo global guardado: {global_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7\ufe0f\u20e3 Entrenar Modelos por Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\ud83c\udfaf MODELOS ESTRATIFICADOS POR CLUSTER\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "cluster_models = {}\n",
    "cluster_metrics = {}\n",
    "cluster_predictions = {}\n",
    "\n",
    "for cluster_id in sorted(clusters_train.unique()):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"\ud83d\udd2c CLUSTER {cluster_id}\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    # Filtrar datos del cluster\n",
    "    train_mask = clusters_train == cluster_id\n",
    "    test_mask = clusters_test == cluster_id\n",
    "    \n",
    "    X_train_cluster = X_train[train_mask]\n",
    "    y_train_cluster = y_train[train_mask]\n",
    "    X_test_cluster = X_test[test_mask]\n",
    "    \n",
    "    # Saltar clusters con test set vac\u00edo o demasiado peque\u00f1os\n",
    "    if len(X_test_cluster) == 0:\n",
    "        print(f\"\u26a0\ufe0f  Test set vac\u00edo. Saltando Cluster {cluster_id}...\")\n",
    "        print(f\"   Este cluster tiene muy pocas muestras para entrenar un modelo confiable.\\n\")\n",
    "        continue\n",
    "    \n",
    "    if len(X_train_cluster) < 10:\n",
    "        print(f\"\u26a0\ufe0f  Train set muy peque\u00f1o ({len(X_train_cluster)} muestras). Saltando Cluster {cluster_id}...\")\n",
    "        print(f\"   Se requieren al menos 10 muestras para entrenar un modelo confiable.\\n\")\n",
    "        continue\n",
    "    y_test_cluster = y_test[test_mask]\n",
    "    \n",
    "    print(f\"Train samples: {len(X_train_cluster):,}\")\n",
    "    print(f\"Test samples:  {len(X_test_cluster):,}\")\n",
    "    \n",
    "    # Distribuci\u00f3n de clases\n",
    "    print(f\"\\nDistribuci\u00f3n de clases (train):\")\n",
    "    train_dist = Counter(y_train_cluster)\n",
    "    for cls in ['low', 'medium', 'high']:\n",
    "        count = train_dist.get(cls, 0)\n",
    "        pct = count / len(y_train_cluster) * 100 if len(y_train_cluster) > 0 else 0\n",
    "        print(f\"  {cls.upper():8} {count:5,} ({pct:5.1f}%)\")\n",
    "    \n",
    "    # SMOTE si hay suficientes muestras\n",
    "    if len(X_train_cluster) >= 50 and len(train_dist) >= 2:\n",
    "        try:\n",
    "            # Ajustar targets de SMOTE seg\u00fan tama\u00f1o del cluster\n",
    "            cluster_total = len(y_train_cluster)\n",
    "            cluster_high = int(cluster_total * 0.15)\n",
    "            cluster_medium = int(cluster_total * 0.35)\n",
    "            \n",
    "            # Solo aplicar SMOTE si hay al menos 2 muestras de cada clase minoritaria\n",
    "            min_samples = min([v for k, v in train_dist.items() if k in ['medium', 'high']])\n",
    "            \n",
    "            if min_samples >= 2:\n",
    "                smote_cluster = SMOTE(\n",
    "                    sampling_strategy={\n",
    "                        'high': max(cluster_high, train_dist.get('high', 0)),\n",
    "                        'medium': max(cluster_medium, train_dist.get('medium', 0))\n",
    "                    },\n",
    "                    random_state=42\n",
    "                )\n",
    "                \n",
    "                print(\"\\nAplicando SMOTE...\")\n",
    "                X_train_cluster_smote, y_train_cluster_smote = smote_cluster.fit_resample(\n",
    "                    X_train_cluster, y_train_cluster\n",
    "                )\n",
    "                \n",
    "                smote_dist = Counter(y_train_cluster_smote)\n",
    "                print(f\"Distribuci\u00f3n despu\u00e9s de SMOTE:\")\n",
    "                for cls in ['low', 'medium', 'high']:\n",
    "                    count = smote_dist.get(cls, 0)\n",
    "                    pct = count / len(y_train_cluster_smote) * 100\n",
    "                    print(f\"  {cls.upper():8} {count:5,} ({pct:5.1f}%)\")\n",
    "            else:\n",
    "                print(\"\\n\u26a0\ufe0f  Pocas muestras minoritarias, saltando SMOTE\")\n",
    "                X_train_cluster_smote = X_train_cluster\n",
    "                y_train_cluster_smote = y_train_cluster\n",
    "        except Exception as e:\n",
    "            print(f\"\\n\u26a0\ufe0f  Error en SMOTE: {e}\")\n",
    "            print(\"   Continuando sin SMOTE...\")\n",
    "            X_train_cluster_smote = X_train_cluster\n",
    "            y_train_cluster_smote = y_train_cluster\n",
    "    else:\n",
    "        print(\"\\n\u26a0\ufe0f  Cluster peque\u00f1o, entrenando sin SMOTE\")\n",
    "        X_train_cluster_smote = X_train_cluster\n",
    "        y_train_cluster_smote = y_train_cluster\n",
    "    \n",
    "    # Entrenar modelo del cluster\n",
    "    model_cluster = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=15,\n",
    "        min_samples_split=10,\n",
    "        min_samples_leaf=4,\n",
    "        class_weight='balanced',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    print(\"\\nEntrenando modelo...\")\n",
    "    model_cluster.fit(X_train_cluster_smote, y_train_cluster_smote)\n",
    "    print(\"\u2713 Entrenamiento completado\")\n",
    "    \n",
    "    # Evaluar en test set del cluster\n",
    "    y_pred_cluster = model_cluster.predict(X_test_cluster)\n",
    "    \n",
    "    # Detectar clases \u00fanicas presentes en test set\n",
    "    unique_classes = sorted(y_test_cluster.unique())\n",
    "    target_names_cluster = [cls for cls in ['low', 'medium', 'high'] if cls in unique_classes]\n",
    "    \n",
    "    print(\"\\n\ud83d\udcca M\u00e9tricas del Cluster:\\n\")\n",
    "    if len(unique_classes) < 3:\n",
    "        print(f\"\u26a0\ufe0f  Test set solo tiene {len(unique_classes)} clases: {unique_classes}\")\n",
    "    print(classification_report(y_test_cluster, y_pred_cluster,\n",
    "                              target_names=target_names_cluster,\n",
    "                              digits=3,\n",
    "                              zero_division=0))\n",
    "    \n",
    "    # Guardar m\u00e9tricas\n",
    "    cluster_metrics[cluster_id] = {\n",
    "        'accuracy': accuracy_score(y_test_cluster, y_pred_cluster),\n",
    "        'f1_macro': f1_score(y_test_cluster, y_pred_cluster, average='macro', zero_division=0),\n",
    "        'f1_low': f1_score(y_test_cluster, y_pred_cluster, labels=['low'], average='macro', zero_division=0),\n",
    "        'f1_medium': f1_score(y_test_cluster, y_pred_cluster, labels=['medium'], average='macro', zero_division=0),\n",
    "        'f1_high': f1_score(y_test_cluster, y_pred_cluster, labels=['high'], average='macro', zero_division=0),\n",
    "        'recall_high': recall_score(y_test_cluster, y_pred_cluster, labels=['high'], average='macro', zero_division=0),\n",
    "        'precision_high': precision_score(y_test_cluster, y_pred_cluster, labels=['high'], average='macro', zero_division=0),\n",
    "        'n_train': len(X_train_cluster),\n",
    "        'n_test': len(X_test_cluster)\n",
    "    }\n",
    "    \n",
    "    # Guardar modelo y predicciones\n",
    "    cluster_models[cluster_id] = model_cluster\n",
    "    cluster_predictions[cluster_id] = {\n",
    "        'y_true': y_test_cluster,\n",
    "        'y_pred': y_pred_cluster\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n\u2713 Cluster {cluster_id} completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8\ufe0f\u20e3 Comparar: Global vs Cluster-Specific"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\ud83d\udcca COMPARACI\u00d3N: Modelo Global vs Modelos por Cluster\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Calcular m\u00e9tricas agregadas de modelos por cluster\n",
    "# (promedio ponderado por tama\u00f1o del cluster)\n",
    "total_test_samples = sum([m['n_test'] for m in cluster_metrics.values()])\n",
    "\n",
    "weighted_cluster_metrics = {\n",
    "    'accuracy': sum([m['accuracy'] * m['n_test'] for m in cluster_metrics.values()]) / total_test_samples,\n",
    "    'f1_macro': sum([m['f1_macro'] * m['n_test'] for m in cluster_metrics.values()]) / total_test_samples,\n",
    "    'f1_low': sum([m['f1_low'] * m['n_test'] for m in cluster_metrics.values()]) / total_test_samples,\n",
    "    'f1_medium': sum([m['f1_medium'] * m['n_test'] for m in cluster_metrics.values()]) / total_test_samples,\n",
    "    'f1_high': sum([m['f1_high'] * m['n_test'] for m in cluster_metrics.values()]) / total_test_samples,\n",
    "    'recall_high': sum([m['recall_high'] * m['n_test'] for m in cluster_metrics.values()]) / total_test_samples,\n",
    "    'precision_high': sum([m['precision_high'] * m['n_test'] for m in cluster_metrics.values()]) / total_test_samples\n",
    "}\n",
    "\n",
    "# Tabla comparativa\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Modelo Global': global_metrics,\n",
    "    'Modelos por Cluster (avg)': weighted_cluster_metrics\n",
    "}).T\n",
    "\n",
    "print(\"\\n\ud83d\udcc8 M\u00e9tricas Comparativas:\\n\")\n",
    "print(comparison_df.round(4))\n",
    "\n",
    "# Calcular diferencias\n",
    "print(\"\\n\ud83d\udcca Diferencias (Cluster - Global):\\n\")\n",
    "for metric in comparison_df.columns:\n",
    "    diff = weighted_cluster_metrics[metric] - global_metrics[metric]\n",
    "    pct_change = (diff / global_metrics[metric]) * 100 if global_metrics[metric] > 0 else 0\n",
    "    symbol = '\ud83d\udcc8' if diff > 0 else '\ud83d\udcc9' if diff < 0 else '\u27a1\ufe0f'\n",
    "    print(f\"  {symbol} {metric:20} {diff:+.4f} ({pct_change:+.2f}%)\")\n",
    "\n",
    "# Visualizar comparaci\u00f3n\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: F1 Scores por clase\n",
    "metrics_to_plot = ['f1_low', 'f1_medium', 'f1_high']\n",
    "x = np.arange(len(metrics_to_plot))\n",
    "width = 0.35\n",
    "\n",
    "global_vals = [global_metrics[m] for m in metrics_to_plot]\n",
    "cluster_vals = [weighted_cluster_metrics[m] for m in metrics_to_plot]\n",
    "\n",
    "axes[0].bar(x - width/2, global_vals, width, label='Global', alpha=0.8)\n",
    "axes[0].bar(x + width/2, cluster_vals, width, label='Cluster-Specific', alpha=0.8)\n",
    "axes[0].set_xlabel('M\u00e9trica')\n",
    "axes[0].set_ylabel('F1-Score')\n",
    "axes[0].set_title('F1-Scores: Global vs Cluster-Specific', fontweight='bold')\n",
    "axes[0].set_xticks(x)\n",
    "axes[0].set_xticklabels(['F1 Low', 'F1 Medium', 'F1 High'])\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 2: Accuracy y F1 Macro\n",
    "metrics2 = ['accuracy', 'f1_macro', 'recall_high']\n",
    "x2 = np.arange(len(metrics2))\n",
    "\n",
    "global_vals2 = [global_metrics[m] for m in metrics2]\n",
    "cluster_vals2 = [weighted_cluster_metrics[m] for m in metrics2]\n",
    "\n",
    "axes[1].bar(x2 - width/2, global_vals2, width, label='Global', alpha=0.8)\n",
    "axes[1].bar(x2 + width/2, cluster_vals2, width, label='Cluster-Specific', alpha=0.8)\n",
    "axes[1].set_xlabel('M\u00e9trica')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('M\u00e9tricas Generales: Global vs Cluster-Specific', fontweight='bold')\n",
    "axes[1].set_xticks(x2)\n",
    "axes[1].set_xticklabels(['Accuracy', 'F1 Macro', 'Recall High'])\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/figures/comparison_global_vs_cluster.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9\ufe0f\u20e3 M\u00e9tricas Detalladas por Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear tabla detallada\n",
    "cluster_details = pd.DataFrame(cluster_metrics).T\n",
    "print(\"\\n\ud83d\udcca M\u00e9tricas Detalladas por Cluster:\\n\")\n",
    "print(cluster_details.round(4))\n",
    "\n",
    "# Visualizar m\u00e9tricas por cluster\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics_viz = ['accuracy', 'f1_macro', 'f1_high', 'recall_high']\n",
    "titles = ['Accuracy por Cluster', 'F1 Macro por Cluster', \n",
    "          'F1 High por Cluster', 'Recall High por Cluster']\n",
    "\n",
    "for idx, (metric, title) in enumerate(zip(metrics_viz, titles)):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    cluster_ids = list(cluster_details.index)\n",
    "    values = cluster_details[metric].values\n",
    "    \n",
    "    bars = ax.bar(cluster_ids, values, alpha=0.7, color='steelblue')\n",
    "    ax.axhline(y=global_metrics[metric], color='red', linestyle='--', \n",
    "               linewidth=2, label='Global Model', alpha=0.7)\n",
    "    \n",
    "    ax.set_xlabel('Cluster')\n",
    "    ax.set_ylabel('Score')\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Anotar valores\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../docs/figures/metrics_by_cluster.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd1f Entrenar KMeans para Inferencia de Cluster\n",
    "\n",
    "Para la API: necesitamos un modelo KMeans entrenado con las mismas features que us\u00f3 el clustering original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"\ud83c\udfaf ENTRENAR KMEANS PARA INFERENCIA DE CLUSTER\")\nprint(\"=\"*80 + \"\\n\")\n\n# Cargar cluster_profiles del notebook 01 V2\ntry:\n    cluster_profiles = pd.read_csv('../data/processed/crohn/cluster_profiles.csv', index_col=0)\n    print(\"\u2713 Cluster profiles cargados\")\n    print(cluster_profiles)\nexcept FileNotFoundError:\n    print(\"\u26a0\ufe0f  cluster_profiles.csv no encontrado\")\n    print(\"   Creando profiles simplificados desde datos actuales...\\n\")\n    \n    # Crear profiles desde datos actuales\n    symptom_cols = ['abdominal_pain', 'blood_in_stool', 'diarrhea', 'fatigue', 'fever', 'nausea']\n    cluster_profiles = df.groupby('cluster')[symptom_cols].mean()\n    print(cluster_profiles)\n\n# Features de s\u00edntomas para clustering (igual que notebook 01 V2)\nsymptom_features = ['abdominal_pain', 'blood_in_stool', 'diarrhea', 'fatigue', 'fever', 'nausea']\n\n# Filtrar solo features disponibles\navailable_features = [f for f in symptom_features if f in df.columns]\nprint(f\"\\nFeatures para clustering: {available_features}\")\n\n# Preparar datos para KMeans (usar todos los datos con cluster conocido)\nX_clustering = df[available_features].copy()\ny_clustering = df['cluster'].copy()\n\n# Normalizar (StandardScaler)\nscaler = StandardScaler()\nX_clustering_scaled = scaler.fit_transform(X_clustering)\n\nprint(f\"\\nDatos para KMeans: {X_clustering_scaled.shape}\")\n\n# Entrenar KMeans con k=3\nn_clusters = len(df['cluster'].unique())\nkmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=50)\n\nprint(f\"\\nEntrenando KMeans con k={n_clusters}...\")\nkmeans.fit(X_clustering_scaled)\nprint(\"\u2713 KMeans entrenado\")\n\n# Verificar centroides\nprint(f\"\\nCentroides (escalados):\\n\")\ncentroids_df = pd.DataFrame(\n    kmeans.cluster_centers_,\n    columns=available_features,\n    index=[f'Cluster {i}' for i in range(n_clusters)]\n)\nprint(centroids_df.round(3))\n\n# Guardar scaler y kmeans en directorio Crohn\nwith open('../models/crohn/cluster_scaler.pkl', 'wb') as f:\n    pickle.dump(scaler, f)\nprint(\"\\n\u2713 Scaler guardado: models/crohn/cluster_scaler.pkl\")\n\nwith open('../models/crohn/cluster_kmeans.pkl', 'wb') as f:\n    pickle.dump(kmeans, f)\nprint(\"\u2713 KMeans guardado: models/crohn/cluster_kmeans.pkl\")\n\n# Guardar metadata de clustering\ncluster_metadata = {\n    'ibd_type': 'crohn',\n    'n_clusters': n_clusters,\n    'features': available_features,\n    'trained_date': datetime.now().isoformat(),\n    'n_samples': len(X_clustering)\n}\n\nwith open('../models/crohn/cluster_metadata.json', 'w') as f:\n    json.dump(cluster_metadata, f, indent=2)\nprint(\"\u2713 Metadata guardada: models/crohn/cluster_metadata.json\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\ufe0f\u20e31\ufe0f\u20e3 Guardar Modelos por Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\n\" + \"=\"*80)\nprint(\"\ud83d\udcbe GUARDANDO MODELOS POR CLUSTER - CROHN\")\nprint(\"=\"*80 + \"\\n\")\n\nfor cluster_id, model in cluster_models.items():\n    model_path = f'../models/crohn/rf_severity_classifier_cluster_{cluster_id}.pkl'\n    \n    with open(model_path, 'wb') as f:\n        pickle.dump(model, f)\n    \n    size_mb = Path(model_path).stat().st_size / (1024**2)\n    print(f\"\u2713 Cluster {cluster_id}: {model_path} ({size_mb:.2f} MB)\")\n\n# Guardar metadata de modelos por cluster\ncluster_models_metadata = {\n    'ibd_type': 'crohn',\n    'trained_date': datetime.now().isoformat(),\n    'n_clusters': len(cluster_models),\n    'features': feature_cols,\n    'target': target_col,\n    'model_type': 'RandomForestClassifier',\n    'clusters': {}\n}\n\nfor cluster_id in cluster_models.keys():\n    cluster_models_metadata['clusters'][int(cluster_id)] = {\n        'model_file': f'rf_severity_classifier_cluster_{cluster_id}.pkl',\n        'metrics': {k: float(v) for k, v in cluster_metrics[cluster_id].items() \n                   if k not in ['n_train', 'n_test']},\n        'n_train': int(cluster_metrics[cluster_id]['n_train']),\n        'n_test': int(cluster_metrics[cluster_id]['n_test'])\n    }\n\nwith open('../models/crohn/cluster_models_metadata.json', 'w') as f:\n    json.dump(cluster_models_metadata, f, indent=2)\n\nprint(\"\\n\u2713 Metadata guardada: models/crohn/cluster_models_metadata.json\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\ufe0f\u20e32\ufe0f\u20e3 Guardar Reporte Completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Crear reporte completo\nreport = {\n    'title': 'Cluster-Stratified Model Training Report - CROHN',\n    'ibd_type': 'crohn',\n    'date': datetime.now().isoformat(),\n    'global_model': {\n        'metrics': {k: float(v) for k, v in global_metrics.items()},\n        'model_file': 'rf_severity_classifier.pkl'\n    },\n    'cluster_models': {\n        'weighted_avg_metrics': {k: float(v) for k, v in weighted_cluster_metrics.items()},\n        'individual_clusters': cluster_models_metadata['clusters']\n    },\n    'comparison': {\n        'improvements': {},\n        'recommendation': ''\n    }\n}\n\n# Calcular mejoras\nfor metric in global_metrics.keys():\n    diff = weighted_cluster_metrics[metric] - global_metrics[metric]\n    pct_change = (diff / global_metrics[metric]) * 100 if global_metrics[metric] > 0 else 0\n    report['comparison']['improvements'][metric] = {\n        'absolute_diff': float(diff),\n        'percent_change': float(pct_change),\n        'improved': bool(diff > 0)\n    }\n\n# Recomendaci\u00f3n\nf1_high_improved = report['comparison']['improvements']['f1_high']['improved']\nrecall_high_improved = report['comparison']['improvements']['recall_high']['improved']\n\nif f1_high_improved and recall_high_improved:\n    report['comparison']['recommendation'] = \"USAR MODELOS POR CLUSTER: Mejoran las m\u00e9tricas clave (F1 y Recall de HIGH)\"\nelif f1_high_improved or recall_high_improved:\n    report['comparison']['recommendation'] = \"EVALUAR: Mejora parcial en m\u00e9tricas clave. Considerar trade-offs.\"\nelse:\n    report['comparison']['recommendation'] = \"MANTENER MODELO GLOBAL: Los modelos por cluster no mejoran significativamente\"\n\n# Guardar reporte\nreport_path = '../reports/crohn_cluster_stratified_training_report.json'\nwith open(report_path, 'w') as f:\n    json.dump(report, f, indent=2)\n\nprint(f\"\\n\u2713 Reporte completo guardado: {report_path}\")\n\n# Mostrar recomendaci\u00f3n\nprint(\"\\n\" + \"=\"*80)\nprint(\"\ud83d\udca1 RECOMENDACI\u00d3N FINAL - CROHN\")\nprint(\"=\"*80)\nprint(f\"\\n{report['comparison']['recommendation']}\")\nprint(\"\\n\" + \"=\"*80)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## \u2705 Resumen del Notebook - CROHN\n\n### Lo que hemos logrado:\n\n1. \u2705 Entrenado **3 modelos RF** (uno por cluster de fenotipo para CROHN)\n2. \u2705 Comparado m\u00e9tricas: **Global vs Cluster-Specific**\n3. \u2705 Guardado modelos por cluster + KMeans + Scaler para inferencia\n4. \u2705 Generado reporte completo con recomendaci\u00f3n\n\n### Archivos generados:\n\n- `models/crohn/rf_severity_classifier_cluster_0.pkl` - Modelo Cluster 0\n- `models/crohn/rf_severity_classifier_cluster_1.pkl` - Modelo Cluster 1\n- `models/crohn/rf_severity_classifier_cluster_2.pkl` - Modelo Cluster 2\n- `models/crohn/cluster_kmeans.pkl` - KMeans para inferir cluster de nuevos usuarios\n- `models/crohn/cluster_scaler.pkl` - StandardScaler para normalizar features\n- `models/crohn/cluster_models_metadata.json` - Metadata de modelos\n- `models/crohn/cluster_metadata.json` - Metadata de clustering\n- `reports/crohn_cluster_stratified_training_report.json` - Reporte completo\n\n### Pr\u00f3ximos pasos:\n\n1. **Notebook 05**: Entrenar modelos para Colitis Ulcerosa\n2. **Actualizar API** (`api/ml_model.py`) - Ya actualizada para soportar Crohn y CU\n3. **Probar API** con nuevos endpoints\n4. **Evaluar en producci\u00f3n** y monitorear m\u00e9tricas"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
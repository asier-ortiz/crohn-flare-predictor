.PHONY: help install sync clean test format lint serve notebook docker-build docker-run
.PHONY: kill-serve run-notebook-02 run-notebook-03 pipeline reports show-latest-report

# Variables
PYTHON := uv run python
PYTEST := uv run pytest
BLACK := uv run black
FLAKE8 := uv run flake8
JUPYTER := uv run jupyter
UVICORN := uv run uvicorn

help: ## Mostrar este mensaje de ayuda
	@echo "Comandos disponibles:"
	@grep -E '^[a-zA-Z_-]+:.*?## .*$$' $(MAKEFILE_LIST) | awk 'BEGIN {FS = ":.*?## "}; {printf "\033[36m%-20s\033[0m %s\n", $$1, $$2}'

install: ## Instalar uv (gestor de paquetes)
	@echo "Instalando uv..."
	@curl -LsSf https://astral.sh/uv/install.sh | sh || pip install uv

sync: ## Sincronizar e instalar todas las dependencias
	@echo "Instalando dependencias con uv..."
	uv sync
	@echo "âœ… Dependencias instaladas correctamente"

clean: ## Limpiar archivos temporales y cache
	@echo "Limpiando archivos temporales..."
	find . -type d -name "__pycache__" -exec rm -rf {} + 2>/dev/null || true
	find . -type d -name ".pytest_cache" -exec rm -rf {} + 2>/dev/null || true
	find . -type d -name ".coverage" -exec rm -rf {} + 2>/dev/null || true
	find . -type d -name "htmlcov" -exec rm -rf {} + 2>/dev/null || true
	find . -type f -name "*.pyc" -delete 2>/dev/null || true
	find . -type d -name "*.egg-info" -exec rm -rf {} + 2>/dev/null || true
	@echo "âœ… Limpieza completada"

test: ## Ejecutar tests con pytest
	@echo "Ejecutando tests..."
	$(PYTEST)

test-cov: ## Ejecutar tests con cobertura
	@echo "Ejecutando tests con cobertura..."
	$(PYTEST) --cov=src --cov-report=html --cov-report=term
	@echo "ğŸ“Š Reporte de cobertura generado en htmlcov/index.html"

format: ## Formatear cÃ³digo con Black
	@echo "Formateando cÃ³digo..."
	$(BLACK) src/ api/ tests/ scripts/
	@echo "âœ… CÃ³digo formateado"

lint: ## Verificar cÃ³digo con flake8
	@echo "Verificando cÃ³digo..."
	$(FLAKE8) src/ api/ tests/ scripts/
	@echo "âœ… VerificaciÃ³n completada"

check: format lint test ## Ejecutar formato, lint y tests

serve: ## Iniciar servidor API en modo desarrollo
	@echo "ğŸš€ Iniciando servidor API..."
	@echo "DocumentaciÃ³n disponible en:"
	@echo "  - Swagger UI: http://localhost:8001/docs"
	@echo "  - ReDoc: http://localhost:8001/redoc"
	$(UVICORN) api.app:app --reload --host 0.0.0.0 --port 8001

kill-serve: ## Detener servidor API (libera puerto 8001)
	@echo "ğŸ›‘ Deteniendo servidor en puerto 8001..."
	@lsof -ti :8001 | xargs kill -9 2>/dev/null || echo "âœ… Puerto 8001 ya estÃ¡ libre"

serve-prod: ## Iniciar servidor API en modo producciÃ³n
	@echo "ğŸš€ Iniciando servidor API (producciÃ³n)..."
	$(UVICORN) api.app:app --host 0.0.0.0 --port 8001 --workers 4

test-api: ## Probar endpoints de la API (requiere servidor activo)
	@echo "ğŸ§ª Probando API..."
	$(PYTHON) scripts/test_api.py

test-api-curl: ## Probar API con curl (requiere jq instalado)
	@echo "ğŸ§ª Probando API con curl..."
	./scripts/test_api.sh

evaluate: ## Evaluar precisiÃ³n del modelo (requiere servidor activo)
	@echo "ğŸ”¬ Evaluando modelo..."
	$(PYTHON) scripts/evaluate_model.py

notebook: ## Iniciar Jupyter Notebook (con entorno virtual)
	@echo "ğŸ““ Iniciando Jupyter Notebook..."
	@echo "âš™ï¸  Usando entorno virtual de uv"
	uv run jupyter notebook

lab: ## Iniciar Jupyter Lab (con entorno virtual)
	@echo "ğŸ““ Iniciando Jupyter Lab..."
	@echo "âš™ï¸  Usando entorno virtual de uv"
	uv run jupyter lab

train: ## Ejecutar entrenamiento completo (notebooks 02 y 03)
	@echo "ğŸ¤– Ejecutando pipeline de entrenamiento..."
	@echo "ğŸ“Š Paso 1/2: Feature Engineering (notebook 02)..."
	uv run jupyter nbconvert --to notebook --execute notebooks/02_feature_engineering.ipynb --inplace
	@echo "âœ… Features generadas"
	@echo "ğŸ“Š Paso 2/2: Model Training (notebook 03)..."
	uv run jupyter nbconvert --to notebook --execute notebooks/03_model_training.ipynb --inplace
	@echo "âœ… Modelo entrenado y guardado en models/"

run-notebook-02: ## Ejecutar solo notebook 02 (Feature Engineering)
	@echo "ğŸ“Š Ejecutando Feature Engineering..."
	uv run jupyter nbconvert --to notebook --execute notebooks/02_feature_engineering.ipynb --inplace
	@echo "âœ… Dataset procesado guardado en data/processed/"

run-notebook-03: ## Ejecutar solo notebook 03 (Model Training)
	@echo "ğŸ¤– Ejecutando Model Training..."
	uv run jupyter nbconvert --to notebook --execute notebooks/03_model_training.ipynb --inplace
	@echo "âœ… Modelo guardado en models/"

predict: ## Ejecutar predicciÃ³n de ejemplo
	@echo "ğŸ”® Ejecutando predicciÃ³n..."
	$(PYTHON) -m src.model --predict

setup-data: ## Crear estructura de directorios para datos
	@echo "ğŸ“ Creando estructura de directorios..."
	mkdir -p data/raw data/processed models logs reports/evaluations docs/figures
	@echo "âœ… Directorios creados:"
	@echo "   - data/raw data/processed"
	@echo "   - models logs"
	@echo "   - reports/evaluations"
	@echo "   - docs/figures"
	@echo "âš ï¸  Recuerda descargar el dataset de Kaggle en data/raw/"

dev: sync setup-data ## Setup completo para desarrollo
	@echo "âœ… Entorno de desarrollo listo"
	@echo "Ejecuta 'make notebook' para empezar a analizar datos"
	@echo "Ejecuta 'make serve' para levantar la API"

pipeline: train ## Pipeline completo: entrenar modelo
	@echo ""
	@echo "âœ… Pipeline de entrenamiento completado"
	@echo ""
	@echo "ğŸ“‹ PrÃ³ximos pasos:"
	@echo "  1. make serve          - Iniciar servidor API"
	@echo "  2. make evaluate       - Evaluar modelo (en otra terminal)"
	@echo "  3. make info           - Ver estado del proyecto"

# Docker commands (si decides usar Docker mÃ¡s adelante)
docker-build: ## Construir imagen Docker
	docker build -t crohn-flare-predictor:latest .

docker-run: ## Ejecutar contenedor Docker
	docker run -p 8000:8000 crohn-flare-predictor:latest

# Comandos de utilidad
add: ## Agregar nueva dependencia (uso: make add PKG=nombre-paquete)
	uv add $(PKG)

remove: ## Remover dependencia (uso: make remove PKG=nombre-paquete)
	uv remove $(PKG)

update: ## Actualizar todas las dependencias
	uv sync --upgrade

lock: ## Actualizar lockfile sin instalar
	uv lock

shell: ## Abrir shell en el entorno virtual
	uv run bash

python: ## Abrir Python REPL en el entorno
	$(PYTHON)

info: ## Mostrar informaciÃ³n del proyecto
	@echo "ğŸ“‹ InformaciÃ³n del Proyecto"
	@echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
	@echo "Nombre: crohn-flare-predictor"
	@echo "VersiÃ³n: 1.0.0"
	@echo "Python: $(shell $(PYTHON) --version)"
	@echo ""
	@echo "ğŸ“Š Estado del Modelo:"
	@if [ -f models/rf_severity_classifier.pkl ]; then \
		echo "  âœ… Modelo entrenado: models/rf_severity_classifier.pkl"; \
		ls -lh models/rf_severity_classifier.pkl | awk '{print "     TamaÃ±o: " $$5 " - Modificado: " $$6 " " $$7 " " $$8}'; \
	else \
		echo "  âŒ No hay modelo entrenado (ejecuta: make train)"; \
	fi
	@echo ""
	@echo "ğŸ“‚ Datasets:"
	@if [ -f data/processed/ml_dataset.csv ]; then \
		echo "  âœ… Dataset procesado: data/processed/ml_dataset.csv"; \
		ls -lh data/processed/ml_dataset.csv | awk '{print "     TamaÃ±o: " $$5}'; \
	else \
		echo "  âŒ Dataset no procesado (ejecuta: make run-notebook-02)"; \
	fi
	@echo ""
	@echo "ğŸ“¦ Dependencias principales:"
	@uv pip list | grep -E "(fastapi|scikit-learn|pandas|uvicorn|imbalanced-learn)" || true

reports: ## Ver Ãºltimos reportes de evaluaciÃ³n
	@echo "ğŸ“Š Ãšltimos Reportes de EvaluaciÃ³n"
	@echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
	@if [ -d reports/evaluations ]; then \
		ls -lt reports/evaluations/*.json 2>/dev/null | head -5 | while read -r line; do \
			file=$$(echo $$line | awk '{print $$NF}'); \
			date=$$(echo $$line | awk '{print $$6, $$7, $$8}'); \
			echo "  ğŸ“„ $$(basename $$file) - $$date"; \
		done || echo "  âš ï¸  No hay reportes aÃºn (ejecuta: make evaluate)"; \
	else \
		echo "  âš ï¸  Directorio reports/evaluations no existe"; \
	fi
	@echo ""
	@echo "ğŸ’¡ Para ver un reporte: cat reports/evaluations/evaluation_YYYYMMDD_HHMMSS.json | jq"

show-latest-report: ## Mostrar Ãºltimo reporte de evaluaciÃ³n
	@echo "ğŸ“Š Ãšltimo Reporte de EvaluaciÃ³n"
	@echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
	@latest=$$(ls -t reports/evaluations/*.json 2>/dev/null | head -1); \
	if [ -n "$$latest" ]; then \
		echo "ğŸ“„ Archivo: $$(basename $$latest)"; \
		echo ""; \
		cat "$$latest" | $(PYTHON) -m json.tool; \
	else \
		echo "âš ï¸  No hay reportes disponibles"; \
		echo "ğŸ’¡ Ejecuta: make evaluate (requiere servidor activo)"; \
	fi
